{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook description\n",
    "\n",
    "#### What is this notebook for? \n",
    "This this the first notebook of a serie of five. Its main purpose is to collect the data that will be used for the rest of the project. \n",
    "\n",
    "\n",
    "The process of data collection will be divided in multiple processes: \n",
    "1. Create a list of pages/account where I found bots' comments \n",
    "2. For each, I look at their last 50+ posts to collect the ID of the post \n",
    "3. Once done, loop through those thousands of IDs to collect the comments\n",
    "4. \n",
    "\n",
    "\n",
    "\n",
    "collected the IDs of  from multiple pages suseptible to have bots commenting on their posts. I selected those pages manually by making sure they're all bots' targets. Then, I'll loop through each post thanks to it's ID. On instagram, each post url is made as `instagram.com/p/{postid}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Personnal module, functions I use often\n",
    "import src.webscraping as mw\n",
    "import src.useful as mu\n",
    "\n",
    "\n",
    "# Better print \n",
    "from tqdm import tqdm\n",
    "\n",
    "# To become Dr Strange \n",
    "import time \n",
    "from datetime import datetime\n",
    "\n",
    "# Basic data \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Store data \n",
    "import sqlite3\n",
    "import json\n",
    "from flatten_json import flatten\n",
    "\n",
    "# Move things around locally\n",
    "import shutil\n",
    "\n",
    "# Fetch instagram data \n",
    "from instaloader import Instaloader, Profile\n",
    "from instaloader.exceptions import ProfileNotExistsException\n",
    "import urllib\n",
    "from splinter import Browser\n",
    "\n",
    "import os\n",
    "\n",
    "from coolname import generate_slug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting notebook preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating SQL database to store all the data for this project\n",
    "database = \"data/main_database.sqlite\"\n",
    "con = sqlite3.connect(database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect post ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List a number of instagram accounts that have bots commenting on their posts. Here I'm looping through a page list that is targeted by bots and collect the posts_ids one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing pages targeted by bots\n",
    "pages = [\"nfl\", \"championsleague\", \"mercedesamgf1\", \"ESPN\", \"bleacherreport\", \"houseofhighlights\", \"nba\", \"worldstar\", \"grmdaily\", \"pubity\", \n",
    "         \"meme.ig\", \"brgridiron\", \"lakers\", \"ballislife\", \"nflonfox\", \"nflnetwork\", \"espnnfl\", \"cbssports\", \"thecheckdown\"]\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lunch browser\n",
    "browser = Browser('chrome')\n",
    "\n",
    "post_per_page = 50\n",
    "for page in pages:\n",
    "    browser.visit(f\"https://www.instagram.com/{page}/\")\n",
    "    postids = []\n",
    "    \n",
    "\n",
    "    while len(postids) < post_per_page:\n",
    "        # Scroll up and then down each time helps the page to not bug\n",
    "        browser.execute_script(\"window.scrollTo(0, 0);\")\n",
    "        time.sleep(0.5)\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Instagram doesn't show in the html the posts it of the post we don't see so I need to slowly scroll down to collect each of them.\n",
    "        browser.execute_script(\"window.scrollBy(0, 200);\")\n",
    "\n",
    "        # Change the browser to a beautiful soup object where I can get the posts id\n",
    "        soup = mw.bsoup(browser)\n",
    "        for element in soup.find_all(\"a\"):\n",
    "            link = element.get(\"href\")\n",
    "            if \"/p/\" in link: # We can find the posts id by looking into a tags that have an attribute of href.\n",
    "                postids.append(link.replace(\"/p/\", \"\").replace(\"/\", \"\"))\n",
    "\n",
    "        # Create a df with post_ids and save it in the db\n",
    "        df_post_ids = pd.DataFrame(set(postids), columns=[\"post_id\"])\n",
    "        df_post_ids['page'] = page\n",
    "        df_post_ids.to_sql(\"post_ids\", con, if_exists=\"append\", index=False)\n",
    "\n",
    "        # Display random timer to do nothing\n",
    "        for i in list(range(np.random.randint(10, 30)))[::-1]:\n",
    "            print(i, end=\"\\r\")\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scrape comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>page_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CY23Dx-hQzz</td>\n",
       "      <td>br_hoops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CYhycdhh__L</td>\n",
       "      <td>br_hoops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXpjIIagKAx</td>\n",
       "      <td>br_hoops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CYxi2doBjWu</td>\n",
       "      <td>br_hoops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CYDVbgjhJEq</td>\n",
       "      <td>br_hoops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7826</th>\n",
       "      <td>CWIYygLtmsJ</td>\n",
       "      <td>mercedesamgf1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7827</th>\n",
       "      <td>CZhKJh_uJne</td>\n",
       "      <td>mercedesamgf1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7828</th>\n",
       "      <td>CWROwfUMZR4</td>\n",
       "      <td>mercedesamgf1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7829</th>\n",
       "      <td>CYWw8V4tRPD</td>\n",
       "      <td>mercedesamgf1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7830</th>\n",
       "      <td>CYi8IhRNilj</td>\n",
       "      <td>mercedesamgf1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7831 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          post_id      page_name\n",
       "0     CY23Dx-hQzz       br_hoops\n",
       "1     CYhycdhh__L       br_hoops\n",
       "2     CXpjIIagKAx       br_hoops\n",
       "3     CYxi2doBjWu       br_hoops\n",
       "4     CYDVbgjhJEq       br_hoops\n",
       "...           ...            ...\n",
       "7826  CWIYygLtmsJ  mercedesamgf1\n",
       "7827  CZhKJh_uJne  mercedesamgf1\n",
       "7828  CWROwfUMZR4  mercedesamgf1\n",
       "7829  CYWw8V4tRPD  mercedesamgf1\n",
       "7830  CYi8IhRNilj  mercedesamgf1\n",
       "\n",
       "[7831 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query post_id not in comments table \n",
    "query = \"\"\"\n",
    "SELECT  \n",
    "    DISTINCT\n",
    "    post_id\n",
    "    , page_name\n",
    "FROM post_ids \n",
    "\"\"\"\n",
    "\n",
    "# Loadind post_ids from db\n",
    "posts_ids_to_scrape = pd.read_sql_query(query, con)\n",
    "posts_ids_to_scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping and storing comments from post_ids:\n",
    "np.random.shuffle(posts_ids_to_scrape)\n",
    "for post_id in tqdm(posts_ids_to_scrape):\n",
    "    browser.visit(f\"https://www.instagram.com/p/{post_id}/\")\n",
    "    \n",
    "    # Wait for page to load and get its soup\n",
    "    while True: \n",
    "        soup = mw.bsoup(browser)\n",
    "        if soup.find(\"h2\", class_=\"_a9zc\") != None: \n",
    "            break\n",
    "\n",
    "    # Get days since posted\n",
    "    post_posted_time = soup.find(\"time\", class_=\"_a9ze _a9zf\").get(\"datetime\")\n",
    "    now = datetime.now()\n",
    "    days_diff = (now - pd.to_datetime(post_posted_time[:-1])).days\n",
    "\n",
    "    # I only keep what was posted less than a month ago so I don't get too old data\n",
    "    if days_diff > 31: \n",
    "        continue\n",
    "    \n",
    "    df_post_comments = pd.DataFrame(columns=[\"post_id\", \"page\", \"legend\", \"post_posted_time\", \"username\", \n",
    "                                             \"full_comment_data\", \"comment\", \"comment_posted_time\", \n",
    "                                             \"time_since_posted\", \"comments_likes\", \"replies\",\n",
    "                                             \"time_now\"])\n",
    "\n",
    "    for comment_block in soup.find_all(\"ul\", class_=\"_a9ym\"):\n",
    "        page = soup.find(\"h2\", class_=\"_a9zc\").text \n",
    "        legend = soup.find(\"div\", class_=\"_a9zs\").text \n",
    "        time_since_posted = comment_block.find(\"time\", class_=\"_a9ze _a9zf\").text \n",
    "        username = comment_block.find(\"h3\", class_=\"_a9zc\").text \n",
    "        comment_posted_time = comment_block.find(\"time\", class_=\"_a9ze _a9zf\").get(\"datetime\")\n",
    "        comments_likes = comment_block.find(\"button\", class_=\"_a9ze\").text \n",
    "        comment = comment_block.find(\"div\", class_=\"_a9zs\").text  \n",
    "        replies = comment_block.find(\"li\", class_=\"_a9yg\").text if comment_block.find(\"li\", class_=\"_a9yg\") != None else \"\"\n",
    "        full_comment_data = comment_block.text\n",
    "        time_now = datetime.now()\n",
    "\n",
    "        # Add comment values to dataframe\n",
    "        df_post_comments.loc[len(df_post_comments)] = [post_id, page, legend, post_posted_time, username, \n",
    "                                                       full_comment_data, comment, comment_posted_time, \n",
    "                                                       time_since_posted, comments_likes, replies,\n",
    "                                                       time_now]\n",
    "\n",
    "        \n",
    "    df_post_comments.to_sql(\"comments\", con, if_exists=\"append\", index=False)\n",
    "    time.sleep(np.random.randint(40, 60))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cooler name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post_comments = pd.read_sql_query('select distinct username from comments', con)\n",
    "all_usernames = df_post_comments['username']\n",
    "\n",
    "# Get a cool name for each user and store the mapping in the database\n",
    "cooler_names = {username: generate_slug(3) for index, username in enumerate(all_usernames)}\n",
    "df_username_mapping = pd.DataFrame(cooler_names.items(), columns=['username', 'cooler_name'])\n",
    "df_username_mapping.to_sql(\"username_mapping\", con, index=False)\n",
    "\n",
    "\n",
    "# Mapping usernames \n",
    "df_post_comments['username'] = df_post_comments['username'].map(cooler_names)\n",
    "df_post_comments.to_sql(\"comments\", con, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Collect user data from comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate Instaloader\n",
    "L = Instaloader()\n",
    "\n",
    "def fetch_user_data (username):\n",
    "    '''Function to fetch an Instagram user's public data.\n",
    "\n",
    "    Parameter: \n",
    "        username str: username of the user to collect the \n",
    "        data from.\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        profile = Profile.from_username(L.context, username)\n",
    "    except ProfileNotExistsException:\n",
    "        return f\"{username} does not exists anymore\"\n",
    "        \n",
    "    data = profile.__dict__\n",
    "    del data[\"_context\"]\n",
    "    json_object = json.dumps(data, indent = 2)   \n",
    "    with open(f\"data/users_json/{username}_user_profile_data.json\", 'w') as file_object:  \n",
    "        json.dump(json_object, file_object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json (username):\n",
    "    # Open json \n",
    "    try:\n",
    "        json_file = open(f\"data/users_json/{username}_user_profile_data.json\")\n",
    "        data = json.loads(json.load(json_file))[\"_node\"]\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        return\n",
    "\n",
    "    # Useless json keys\n",
    "    ban = ['edge_felix_video_timeline', 'edge_owner_to_timeline_media', 'edge_saved_media', \n",
    "            'edge_media_collections', 'edge_related_profiles']\n",
    "\n",
    "    # Defining basic keys. Those are name, follower count, bio, etc. Basic infos\n",
    "    basic_keys = [key for key in data.keys() if key not in ban]\n",
    "    basic_info = flatten({key:data[key] for key in basic_keys})\n",
    "    df_current_user = pd.DataFrame([basic_info])\n",
    "\n",
    "    # Getting the data for all posts that are contained in lists. \n",
    "    df_current_user[\"video_count\"] = data['edge_felix_video_timeline'][\"count\"]\n",
    "    df_current_user[\"post_count\"] = data['edge_owner_to_timeline_media'][\"count\"]\n",
    "\n",
    "    last_12_posts = dict()\n",
    "    posts = data['edge_owner_to_timeline_media'][\"edges\"]\n",
    "    last_12_posts[\"username\"] = data[\"username\"]\n",
    "    last_12_posts[\"video_views\"] = [post[\"node\"][\"video_view_count\"] if \"video_view_count\" in post[\"node\"].keys() else np.nan for post in posts]\n",
    "    last_12_posts[\"display_url\"] = [post[\"node\"][\"display_url\"] for post in posts]\n",
    "    last_12_posts[\"thumbnail_src\"] = [post[\"node\"][\"thumbnail_src\"] for post in posts]\n",
    "    last_12_posts[\"accessibility_caption\"] = [post[\"node\"][\"accessibility_caption\"] for post in posts]\n",
    "    last_12_posts[\"is_video\"] = [post[\"node\"][\"is_video\"] for post in posts]\n",
    "    last_12_posts[\"likes\"] = [post[\"node\"][\"edge_liked_by\"][\"count\"] for post in posts]\n",
    "    last_12_posts[\"comments\"] = [post[\"node\"][\"edge_media_to_comment\"][\"count\"] for post in posts]\n",
    "    last_12_posts[\"timestamp\"] = [post[\"node\"][\"taken_at_timestamp\"] for post in posts]\n",
    "    df_last_12_posts = pd.DataFrame(last_12_posts)\n",
    "\n",
    "\n",
    "    # Changing list type to str as sqlite3 doesn't accept this type\n",
    "    list_features = ['bio_links', 'biography_with_entities_entities', 'edge_mutual_followed_by_edges', 'pronouns']\n",
    "    for column in list_features: \n",
    "        if column in df_current_user.columns:\n",
    "            df_current_user[column] = df_current_user[column].apply(lambda x:  \"_LIST_SEPARATOR_\".join(x))\n",
    "\n",
    "    return df_current_user, df_last_12_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usernames to scrape: 88608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:13<00:00,  2.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# Query post_id not in comments table \n",
    "query = \"\"\"\n",
    "SELECT  \n",
    "    DISTINCT\n",
    "    username\n",
    "FROM comments \n",
    "WHERE 1=1\n",
    "    AND username NOT IN (SELECT username FROM users)\n",
    "\"\"\"\n",
    "\n",
    "# Loading usernames to scrape from db\n",
    "usernames_to_scrape = pd.read_sql_query(query, con)[\"username\"]\n",
    "print(f\"Usernames to scrape: {len(usernames_to_scrape)}\")\n",
    "\n",
    "\n",
    "for index, username in enumerate(tqdm(usernames_to_scrape[:5])): \n",
    "    fetch_user_data(username)\n",
    "    \n",
    "    try:\n",
    "        df_current_user, df_current_last_12_posts = convert_json(username)\n",
    "    except FileNotFoundError: # If an error happened while fetching the data, no file\n",
    "        continue\n",
    "\n",
    "    # Not all users have the same numbaer of columns returned and SQL needs same cols to use 'append'\n",
    "    df_users = pd.read_sql_query('select * from users', con)\n",
    "    df_users = pd.concat([df_users, df_current_user]).drop_duplicates()\n",
    "    df_users.to_sql(\"users\", con, if_exists=\"replace\", index=False)\n",
    "    df_current_last_12_posts.to_sql(\"last_12_posts\", con, if_exists=\"append\", index=False)\n",
    "\n",
    "    # Profile pic\n",
    "    for username, profile_pic_url in df_current_user[[\"username\",  \"profile_pic_url\"]].values: \n",
    "        try:\n",
    "            urllib.request.urlretrieve(profile_pic_url, f\"data/photos/user_profile_pictures/{username}_pp_user_photo.png\")\n",
    "        except Exception as e:\n",
    "            print(username, e, end='\\r')\n",
    "\n",
    "    # Last 12 posts\n",
    "    df_current_last_12_posts = df_current_last_12_posts.reset_index()\n",
    "    for username, display_url, index in df_current_last_12_posts[[\"username\", \"display_url\", \"index\"]].values: \n",
    "        urllib.request.urlretrieve(display_url, f\"data/photos/user_last_12_posts/{username}_{index}_user_photo.png\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Screenshot bio url landing page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query users having a link and remove those with NA\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    DISTINCT \n",
    "    username\n",
    "    , external_url \n",
    "FROM users \n",
    "WHERE external_url IS NOT NULL\"\"\"\n",
    "\n",
    "df_user_urls = pd.read_sql_query(query, con)\n",
    "df_user_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:28<00:00,  4.12s/it]\n"
     ]
    }
   ],
   "source": [
    "browser = Browser(\"chrome\")\n",
    "for username, external_url in tqdm(df_user_urls.values):\n",
    "    try:\n",
    "        browser.visit(external_url)\n",
    "        browser.driver.save_screenshot(f\"data/url_screenshot/{username}_external_url_screenshot.png\")\n",
    "        browser = mw.launch_driver(\"/Users/marclamy/Desktop/main file/code/igbot_final/chromedriver\")\n",
    "    except:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Giving cooler names to the users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584202\n",
      "88697\n"
     ]
    }
   ],
   "source": [
    "from coolname import generate_slug\n",
    "\n",
    "# Loading all dfs and creating a list of it\n",
    "df_comments = pd.read_sql_query('select * from comments', con)\n",
    "df_users = pd.read_sql_query('select * from users', con)\n",
    "df_last_12_posts = pd.read_sql_query('select * from last_12_posts', con)\n",
    "all_dfs = [df_comments, df_users, df_last_12_posts]\n",
    "\n",
    "# List all usernames\n",
    "all_usernames = [username for df in all_dfs for username in df['username']]\n",
    "print(len(all_usernames))\n",
    "all_usernames = list(set(all_usernames))\n",
    "print(len(all_usernames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              carrot-mastodon-of-enthusiasm\n",
       "1                   new-statuesque-binturong\n",
       "2                       adorable-jade-beluga\n",
       "3                  hysterical-glistening-bee\n",
       "4                 uber-dragon-of-advertising\n",
       "                         ...                \n",
       "134460                  unique-gaur-of-karma\n",
       "134461                   prudent-rare-dragon\n",
       "134462              grinning-rugged-parakeet\n",
       "134463                  imported-famous-tody\n",
       "134464    important-partridge-of-performance\n",
       "Name: username, Length: 134465, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query('select * from comments', con)[['username']]['username'].map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0     crazy-antelope-of-atheism\n",
       " 1       garrulous-violet-grouse\n",
       " 2             daring-modest-owl\n",
       " 3        tunneling-maroon-potoo\n",
       " 4           merry-silver-grouse\n",
       " 5        amphibian-gifted-mouse\n",
       " 6         funky-original-pigeon\n",
       " 7    delectable-hypnotic-mantis\n",
       " 8    berserk-determined-gazelle\n",
       " 9          natural-heavy-locust\n",
       " Name: username, dtype: object,\n",
       " 0    invisible-fennec-of-teaching\n",
       " 1      invisible-sparkling-avocet\n",
       " 2         sociable-secret-buzzard\n",
       " 3          quaint-elated-starling\n",
       " 4      nostalgic-tactful-mosquito\n",
       " 5     maize-axolotl-of-renovation\n",
       " 6       delectable-gifted-unicorn\n",
       " 7             crafty-caped-ermine\n",
       " 8         festive-mindful-caracal\n",
       " 9        adamant-rhino-of-courage\n",
       " Name: username, dtype: object,\n",
       " 0    crazy-antelope-of-atheism\n",
       " 1    crazy-antelope-of-atheism\n",
       " 2    crazy-antelope-of-atheism\n",
       " 3    crazy-antelope-of-atheism\n",
       " 4    crazy-antelope-of-atheism\n",
       " 5    crazy-antelope-of-atheism\n",
       " 6    crazy-antelope-of-atheism\n",
       " 7    crazy-antelope-of-atheism\n",
       " 8    crazy-antelope-of-atheism\n",
       " 9    crazy-antelope-of-atheism\n",
       " Name: username, dtype: object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users['username'].head(10), df_comments['username'].head(10), df_last_12_posts['username'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>video_views</th>\n",
       "      <th>display_url</th>\n",
       "      <th>thumbnail_src</th>\n",
       "      <th>accessibility_caption</th>\n",
       "      <th>is_video</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>cool_username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crazy-antelope-of-atheism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>Photo shared by ðŸ—£J on November 22, 2021 taggin...</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.637630e+09</td>\n",
       "      <td>crazy-antelope-of-atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crazy-antelope-of-atheism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>Photo by ðŸ—£J on June 17, 2021. May be a closeup...</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.623961e+09</td>\n",
       "      <td>crazy-antelope-of-atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crazy-antelope-of-atheism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>Photo by ðŸ—£J on June 07, 2021. May be an image ...</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.623115e+09</td>\n",
       "      <td>crazy-antelope-of-atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crazy-antelope-of-atheism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>Photo by ðŸ—£J on March 18, 2021. May be an image...</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.616098e+09</td>\n",
       "      <td>crazy-antelope-of-atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crazy-antelope-of-atheism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>https://scontent-lga3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>Photo by ðŸ—£J on February 19, 2021. May be an im...</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.613768e+09</td>\n",
       "      <td>crazy-antelope-of-atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363391</th>\n",
       "      <td>smoky-nippy-malkoha</td>\n",
       "      <td>4238.0</td>\n",
       "      <td>https://scontent-lga3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>https://scontent-lga3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>username                                      ...</td>\n",
       "      <td>1</td>\n",
       "      <td>428.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.641483e+09</td>\n",
       "      <td>smoky-nippy-malkoha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363392</th>\n",
       "      <td>smoky-nippy-malkoha</td>\n",
       "      <td>12531.0</td>\n",
       "      <td>https://scontent-lga3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>https://scontent-lga3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>username                                      ...</td>\n",
       "      <td>1</td>\n",
       "      <td>952.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.641318e+09</td>\n",
       "      <td>smoky-nippy-malkoha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363393</th>\n",
       "      <td>smoky-nippy-malkoha</td>\n",
       "      <td>69105.0</td>\n",
       "      <td>https://scontent-lga3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>https://scontent-lga3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>username                                      ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3584.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.641149e+09</td>\n",
       "      <td>smoky-nippy-malkoha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363394</th>\n",
       "      <td>smoky-nippy-malkoha</td>\n",
       "      <td>96252.0</td>\n",
       "      <td>https://scontent-lga3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>https://scontent-lga3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>username                                      ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5958.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.640449e+09</td>\n",
       "      <td>smoky-nippy-malkoha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363395</th>\n",
       "      <td>smoky-nippy-malkoha</td>\n",
       "      <td>18537.0</td>\n",
       "      <td>https://scontent-lga3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>https://scontent-lga3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>username                                      ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.640219e+09</td>\n",
       "      <td>smoky-nippy-malkoha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363396 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         username  video_views  \\\n",
       "0       crazy-antelope-of-atheism          NaN   \n",
       "1       crazy-antelope-of-atheism          NaN   \n",
       "2       crazy-antelope-of-atheism          NaN   \n",
       "3       crazy-antelope-of-atheism          NaN   \n",
       "4       crazy-antelope-of-atheism          NaN   \n",
       "...                           ...          ...   \n",
       "363391        smoky-nippy-malkoha       4238.0   \n",
       "363392        smoky-nippy-malkoha      12531.0   \n",
       "363393        smoky-nippy-malkoha      69105.0   \n",
       "363394        smoky-nippy-malkoha      96252.0   \n",
       "363395        smoky-nippy-malkoha      18537.0   \n",
       "\n",
       "                                              display_url  \\\n",
       "0       https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "1       https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "2       https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "3       https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "4       https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "...                                                   ...   \n",
       "363391  https://scontent-lga3-1.cdninstagram.com/v/t51...   \n",
       "363392  https://scontent-lga3-1.cdninstagram.com/v/t51...   \n",
       "363393  https://scontent-lga3-1.cdninstagram.com/v/t51...   \n",
       "363394  https://scontent-lga3-1.cdninstagram.com/v/t51...   \n",
       "363395  https://scontent-lga3-1.cdninstagram.com/v/t51...   \n",
       "\n",
       "                                            thumbnail_src  \\\n",
       "0       https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "1       https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "2       https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "3       https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "4       https://scontent-lga3-2.cdninstagram.com/v/t51...   \n",
       "...                                                   ...   \n",
       "363391  https://scontent-lga3-1.cdninstagram.com/v/t51...   \n",
       "363392  https://scontent-lga3-1.cdninstagram.com/v/t51...   \n",
       "363393  https://scontent-lga3-1.cdninstagram.com/v/t51...   \n",
       "363394  https://scontent-lga3-1.cdninstagram.com/v/t51...   \n",
       "363395  https://scontent-lga3-1.cdninstagram.com/v/t51...   \n",
       "\n",
       "                                    accessibility_caption is_video   likes  \\\n",
       "0       Photo shared by ðŸ—£J on November 22, 2021 taggin...        0    34.0   \n",
       "1       Photo by ðŸ—£J on June 17, 2021. May be a closeup...        0    58.0   \n",
       "2       Photo by ðŸ—£J on June 07, 2021. May be an image ...        0    44.0   \n",
       "3       Photo by ðŸ—£J on March 18, 2021. May be an image...        0    36.0   \n",
       "4       Photo by ðŸ—£J on February 19, 2021. May be an im...        0    64.0   \n",
       "...                                                   ...      ...     ...   \n",
       "363391  username                                      ...        1   428.0   \n",
       "363392  username                                      ...        1   952.0   \n",
       "363393  username                                      ...        1  3584.0   \n",
       "363394  username                                      ...        1  5958.0   \n",
       "363395  username                                      ...        1  1505.0   \n",
       "\n",
       "        comments     timestamp              cool_username  \n",
       "0            3.0  1.637630e+09  crazy-antelope-of-atheism  \n",
       "1            7.0  1.623961e+09  crazy-antelope-of-atheism  \n",
       "2            2.0  1.623115e+09  crazy-antelope-of-atheism  \n",
       "3            0.0  1.616098e+09  crazy-antelope-of-atheism  \n",
       "4            4.0  1.613768e+09  crazy-antelope-of-atheism  \n",
       "...          ...           ...                        ...  \n",
       "363391      12.0  1.641483e+09        smoky-nippy-malkoha  \n",
       "363392      11.0  1.641318e+09        smoky-nippy-malkoha  \n",
       "363393      27.0  1.641149e+09        smoky-nippy-malkoha  \n",
       "363394      29.0  1.640449e+09        smoky-nippy-malkoha  \n",
       "363395      11.0  1.640219e+09        smoky-nippy-malkoha  \n",
       "\n",
       "[363396 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_last_12_posts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('main_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:52:09) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06d12861cad82bdcdde1b56bd9eda52e91f7df29dabbeda8f3d9112222750302"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
