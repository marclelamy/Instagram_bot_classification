{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook description\n",
    "\n",
    "#### What is this notebook for? \n",
    "This this the first notebook of a serie of five. Its main purpose is to collect the data that will be used for the rest of the project. \n",
    "\n",
    "\n",
    "The process of data collection will be divided in multiple processes: \n",
    "1. Create a list of pages/account where I found bots' comments \n",
    "2. For each, I look at their last 50+ posts to collect the ID of the post \n",
    "3. Once done, loop through those thousands of IDs to collect the comments\n",
    "4. \n",
    "\n",
    "\n",
    "\n",
    "collected the IDs of  from multiple pages suseptible to have bots commenting on their posts. I selected those pages manually by making sure they're all bots' targets. Then, I'll loop through each post thanks to it's ID. On instagram, each post url is made as `instagram.com/p/{postid}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Personnal module, functions I use often\n",
    "import src.webscraping as mw\n",
    "import src.useful as mu\n",
    "\n",
    "\n",
    "# Better print \n",
    "from tqdm import tqdm\n",
    "\n",
    "# To become Dr Strange \n",
    "import time \n",
    "from datetime import datetime\n",
    "\n",
    "# Basic data \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Store data \n",
    "import sqlite3\n",
    "import json\n",
    "from flatten_json import flatten\n",
    "\n",
    "# Move things around locally\n",
    "import shutil\n",
    "\n",
    "# Fetch instagram data \n",
    "from instaloader import Instaloader, Profile\n",
    "from instaloader.exceptions import ProfileNotExistsException\n",
    "import urllib\n",
    "from splinter import Browser\n",
    "\n",
    "import os\n",
    "\n",
    "from coolname import generate_slug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting notebook preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating SQL database to store all the data for this project\n",
    "database = \"data/main_database.sqlite\"\n",
    "con = sqlite3.connect(database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect post ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List a number of instagram accounts that have bots commenting on their posts. Here I'm looping through a page list that is targeted by bots and collect the posts_ids one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing pages targeted by bots\n",
    "pages = [\"nfl\", \"championsleague\", \"mercedesamgf1\", \"ESPN\", \"bleacherreport\", \"houseofhighlights\", \"nba\", \"worldstar\", \"grmdaily\", \"pubity\", \n",
    "         \"meme.ig\", \"brgridiron\", \"lakers\", \"ballislife\", \"nflonfox\", \"nflnetwork\", \"espnnfl\", \"cbssports\", \"thecheckdown\"]\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SessionNotCreatedException",
     "evalue": "Message: session not created: This version of ChromeDriver only supports Chrome version 104\nCurrent browser version is 110.0.5481.177 with binary path /Applications/Google Chrome.app/Contents/MacOS/Google Chrome\nStacktrace:\n0   chromedriver                        0x0000000102ef6ae0 chromedriver + 3828448\n1   chromedriver                        0x0000000102e8bf1c chromedriver + 3391260\n2   chromedriver                        0x0000000102b84fcc chromedriver + 217036\n3   chromedriver                        0x0000000102ba7a40 chromedriver + 358976\n4   chromedriver                        0x0000000102ba4440 chromedriver + 345152\n5   chromedriver                        0x0000000102ba105c chromedriver + 331868\n6   chromedriver                        0x0000000102bd2254 chromedriver + 533076\n7   chromedriver                        0x0000000102baa010 chromedriver + 368656\n8   chromedriver                        0x0000000102ecc39c chromedriver + 3654556\n9   chromedriver                        0x0000000102ecfc4c chromedriver + 3669068\n10  chromedriver                        0x0000000102ed414c chromedriver + 3686732\n11  chromedriver                        0x0000000102ed0654 chromedriver + 3671636\n12  chromedriver                        0x0000000102eaeb40 chromedriver + 3533632\n13  chromedriver                        0x0000000102ee8414 chromedriver + 3769364\n14  chromedriver                        0x0000000102ee8578 chromedriver + 3769720\n15  chromedriver                        0x0000000102efd0f0 chromedriver + 3854576\n16  libsystem_pthread.dylib             0x00000001bae5c26c _pthread_start + 148\n17  libsystem_pthread.dylib             0x00000001bae5708c thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSessionNotCreatedException\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Lunch browser\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m browser \u001b[38;5;241m=\u001b[39m \u001b[43mBrowser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchrome\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m post_per_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pages:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/main_env/lib/python3.8/site-packages/splinter/browser.py:121\u001b[0m, in \u001b[0;36mBrowser\u001b[0;34m(driver_name, retry_count, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DriverNotFoundError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo driver for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m driver_name)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_driver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/main_env/lib/python3.8/site-packages/splinter/browser.py:96\u001b[0m, in \u001b[0;36mget_driver\u001b[0;34m(driver, retry_count, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m driver_exceptions \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     94\u001b[0m         err \u001b[38;5;241m=\u001b[39m e\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/main_env/lib/python3.8/site-packages/splinter/browser.py:92\u001b[0m, in \u001b[0;36mget_driver\u001b[0;34m(driver, retry_count, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(retry_count):\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdriver\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m driver_exceptions \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     94\u001b[0m         err \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/main_env/lib/python3.8/site-packages/splinter/driver/webdriver/chrome.py:42\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, options, user_agent, wait_time, fullscreen, incognito, headless, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--headless\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m     options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--disable-gpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28msuper\u001b[39m(WebDriver, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(driver, wait_time)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/main_env/lib/python3.8/site-packages/selenium/webdriver/chrome/webdriver.py:69\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m service:\n\u001b[1;32m     67\u001b[0m     service \u001b[38;5;241m=\u001b[39m Service(executable_path, port, service_args, service_log_path)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHROME\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbrowserName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mservice_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_capabilities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mservice_log_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/main_env/lib/python3.8/site-packages/selenium/webdriver/chromium/webdriver.py:92\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChromiumRemoteConnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremote_server_addr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbrowser_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbrowser_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvendor_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvendor_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ignore_proxy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquit()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/main_env/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:277\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authenticator_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_client()\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcapabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbrowser_profile\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/main_env/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:370\u001b[0m, in \u001b[0;36mWebDriver.start_session\u001b[0;34m(self, capabilities, browser_profile)\u001b[0m\n\u001b[1;32m    368\u001b[0m w3c_caps \u001b[38;5;241m=\u001b[39m _make_w3c_caps(capabilities)\n\u001b[1;32m    369\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m: w3c_caps}\n\u001b[0;32m--> 370\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNEW_SESSION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[1;32m    372\u001b[0m     response \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/main_env/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:435\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    433\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[1;32m    437\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/main_env/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py:247\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    245\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mSessionNotCreatedException\u001b[0m: Message: session not created: This version of ChromeDriver only supports Chrome version 104\nCurrent browser version is 110.0.5481.177 with binary path /Applications/Google Chrome.app/Contents/MacOS/Google Chrome\nStacktrace:\n0   chromedriver                        0x0000000102ef6ae0 chromedriver + 3828448\n1   chromedriver                        0x0000000102e8bf1c chromedriver + 3391260\n2   chromedriver                        0x0000000102b84fcc chromedriver + 217036\n3   chromedriver                        0x0000000102ba7a40 chromedriver + 358976\n4   chromedriver                        0x0000000102ba4440 chromedriver + 345152\n5   chromedriver                        0x0000000102ba105c chromedriver + 331868\n6   chromedriver                        0x0000000102bd2254 chromedriver + 533076\n7   chromedriver                        0x0000000102baa010 chromedriver + 368656\n8   chromedriver                        0x0000000102ecc39c chromedriver + 3654556\n9   chromedriver                        0x0000000102ecfc4c chromedriver + 3669068\n10  chromedriver                        0x0000000102ed414c chromedriver + 3686732\n11  chromedriver                        0x0000000102ed0654 chromedriver + 3671636\n12  chromedriver                        0x0000000102eaeb40 chromedriver + 3533632\n13  chromedriver                        0x0000000102ee8414 chromedriver + 3769364\n14  chromedriver                        0x0000000102ee8578 chromedriver + 3769720\n15  chromedriver                        0x0000000102efd0f0 chromedriver + 3854576\n16  libsystem_pthread.dylib             0x00000001bae5c26c _pthread_start + 148\n17  libsystem_pthread.dylib             0x00000001bae5708c thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "# Lunch browser\n",
    "browser = Browser('chrome')\n",
    "\n",
    "post_per_page = 50\n",
    "for page in pages:\n",
    "    browser.visit(f\"https://www.instagram.com/{page}/\")\n",
    "    postids = []\n",
    "    \n",
    "\n",
    "    while len(postids) < post_per_page:\n",
    "        # Scroll up and then down each time helps the page to not bug\n",
    "        browser.execute_script(\"window.scrollTo(0, 0);\")\n",
    "        time.sleep(0.5)\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Instagram doesn't show in the html the posts it of the post we don't see so I need to slowly scroll down to collect each of them.\n",
    "        browser.execute_script(\"window.scrollBy(0, 200);\")\n",
    "\n",
    "        # Change the browser to a beautiful soup object where I can get the posts id\n",
    "        soup = mw.bsoup(browser)\n",
    "        for element in soup.find_all(\"a\"):\n",
    "            link = element.get(\"href\")\n",
    "            if \"/p/\" in link: # We can find the posts id by looking into a tags that have an attribute of href.\n",
    "                postids.append(link.replace(\"/p/\", \"\").replace(\"/\", \"\"))\n",
    "\n",
    "        # Create a df with post_ids and save it in the db\n",
    "        df_post_ids = pd.DataFrame(set(postids), columns=[\"post_id\"])\n",
    "        df_post_ids['page'] = page\n",
    "        df_post_ids.to_sql(\"post_ids\", con, if_exists=\"append\", index=False)\n",
    "\n",
    "        # Display random timer to do nothing\n",
    "        for i in list(range(np.random.randint(10, 30)))[::-1]:\n",
    "            print(i, end=\"\\r\")\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scrape comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query post_id not in comments table \n",
    "query = \"\"\"\n",
    "SELECT  \n",
    "    DISTINCT\n",
    "    post_id\n",
    "    , page_name\n",
    "FROM post_ids \n",
    "\"\"\"\n",
    "\n",
    "# Loadind post_ids from db\n",
    "posts_ids_to_scrape = pd.read_sql_query(query, con)\n",
    "posts_ids_to_scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping and storing comments from post_ids:\n",
    "np.random.shuffle(posts_ids_to_scrape)\n",
    "for post_id in tqdm(posts_ids_to_scrape):\n",
    "    browser.visit(f\"https://www.instagram.com/p/{post_id}/\")\n",
    "    \n",
    "    # Wait for page to load and get its soup\n",
    "    while True: \n",
    "        soup = mw.bsoup(browser)\n",
    "        if soup.find(\"h2\", class_=\"_a9zc\") != None: \n",
    "            break\n",
    "\n",
    "    # Get days since posted\n",
    "    post_posted_time = soup.find(\"time\", class_=\"_a9ze _a9zf\").get(\"datetime\")\n",
    "    now = datetime.now()\n",
    "    days_diff = (now - pd.to_datetime(post_posted_time[:-1])).days\n",
    "\n",
    "    # I only keep what was posted less than a month ago so I don't get too old data\n",
    "    if days_diff > 31: \n",
    "        continue\n",
    "    \n",
    "    df_post_comments = pd.DataFrame(columns=[\"post_id\", \"page\", \"legend\", \"post_posted_time\", \"username\", \n",
    "                                             \"full_comment_data\", \"comment\", \"comment_posted_time\", \n",
    "                                             \"time_since_posted\", \"comments_likes\", \"replies\",\n",
    "                                             \"time_now\"])\n",
    "\n",
    "    for comment_block in soup.find_all(\"ul\", class_=\"_a9ym\"):\n",
    "        page = soup.find(\"h2\", class_=\"_a9zc\").text \n",
    "        legend = soup.find(\"div\", class_=\"_a9zs\").text \n",
    "        time_since_posted = comment_block.find(\"time\", class_=\"_a9ze _a9zf\").text \n",
    "        username = comment_block.find(\"h3\", class_=\"_a9zc\").text \n",
    "        comment_posted_time = comment_block.find(\"time\", class_=\"_a9ze _a9zf\").get(\"datetime\")\n",
    "        comments_likes = comment_block.find(\"button\", class_=\"_a9ze\").text \n",
    "        comment = comment_block.find(\"div\", class_=\"_a9zs\").text  \n",
    "        replies = comment_block.find(\"li\", class_=\"_a9yg\").text if comment_block.find(\"li\", class_=\"_a9yg\") != None else \"\"\n",
    "        full_comment_data = comment_block.text\n",
    "        time_now = datetime.now()\n",
    "\n",
    "        # Add comment values to dataframe\n",
    "        df_post_comments.loc[len(df_post_comments)] = [post_id, page, legend, post_posted_time, username, \n",
    "                                                       full_comment_data, comment, comment_posted_time, \n",
    "                                                       time_since_posted, comments_likes, replies,\n",
    "                                                       time_now]\n",
    "\n",
    "        \n",
    "    df_post_comments.to_sql(\"comments\", con, if_exists=\"append\", index=False)\n",
    "    time.sleep(np.random.randint(40, 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cooler name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post_comments = pd.read_sql_query('select distinct username from comments', con)\n",
    "all_usernames = df_post_comments['username']\n",
    "\n",
    "# Get a cool name for each user and store the mapping in the database\n",
    "cooler_names = {username: generate_slug(3) for index, username in enumerate(all_usernames)}\n",
    "df_username_mapping = pd.DataFrame(cooler_names.items(), columns=['username', 'cooler_name'])\n",
    "df_username_mapping.to_sql(\"username_mapping\", con, index=False)\n",
    "\n",
    "\n",
    "# Mapping usernames \n",
    "df_post_comments['username'] = df_post_comments['username'].map(cooler_names)\n",
    "df_post_comments.to_sql(\"comments\", con, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Collect user data from comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate Instaloader\n",
    "L = Instaloader()\n",
    "\n",
    "def fetch_user_data (username):\n",
    "    '''Function to fetch an Instagram user's public data.\n",
    "\n",
    "    Parameter: \n",
    "        username str: username of the user to collect the \n",
    "        data from.\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        profile = Profile.from_username(L.context, username)\n",
    "    except ProfileNotExistsException:\n",
    "        return f\"{username} does not exists anymore\"\n",
    "        \n",
    "    data = profile.__dict__\n",
    "    del data[\"_context\"]\n",
    "    json_object = json.dumps(data, indent = 2)   \n",
    "    with open(f\"data/users_json/{username}_user_profile_data.json\", 'w') as file_object:  \n",
    "        json.dump(json_object, file_object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json (username):\n",
    "    # Open json \n",
    "    try:\n",
    "        json_file = open(f\"data/users_json/{username}_user_profile_data.json\")\n",
    "        data = json.loads(json.load(json_file))[\"_node\"]\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        return\n",
    "\n",
    "    # Useless json keys\n",
    "    ban = ['edge_felix_video_timeline', 'edge_owner_to_timeline_media', 'edge_saved_media', \n",
    "            'edge_media_collections', 'edge_related_profiles']\n",
    "\n",
    "    # Defining basic keys. Those are name, follower count, bio, etc. Basic infos\n",
    "    basic_keys = [key for key in data.keys() if key not in ban]\n",
    "    basic_info = flatten({key:data[key] for key in basic_keys})\n",
    "    df_current_user = pd.DataFrame([basic_info])\n",
    "\n",
    "    # Getting the data for all posts that are contained in lists. \n",
    "    df_current_user[\"video_count\"] = data['edge_felix_video_timeline'][\"count\"]\n",
    "    df_current_user[\"post_count\"] = data['edge_owner_to_timeline_media'][\"count\"]\n",
    "\n",
    "    last_12_posts = dict()\n",
    "    posts = data['edge_owner_to_timeline_media'][\"edges\"]\n",
    "    last_12_posts[\"username\"] = data[\"username\"]\n",
    "    last_12_posts[\"video_views\"] = [post[\"node\"][\"video_view_count\"] if \"video_view_count\" in post[\"node\"].keys() else np.nan for post in posts]\n",
    "    last_12_posts[\"display_url\"] = [post[\"node\"][\"display_url\"] for post in posts]\n",
    "    last_12_posts[\"thumbnail_src\"] = [post[\"node\"][\"thumbnail_src\"] for post in posts]\n",
    "    last_12_posts[\"accessibility_caption\"] = [post[\"node\"][\"accessibility_caption\"] for post in posts]\n",
    "    last_12_posts[\"is_video\"] = [post[\"node\"][\"is_video\"] for post in posts]\n",
    "    last_12_posts[\"likes\"] = [post[\"node\"][\"edge_liked_by\"][\"count\"] for post in posts]\n",
    "    last_12_posts[\"comments\"] = [post[\"node\"][\"edge_media_to_comment\"][\"count\"] for post in posts]\n",
    "    last_12_posts[\"timestamp\"] = [post[\"node\"][\"taken_at_timestamp\"] for post in posts]\n",
    "    df_last_12_posts = pd.DataFrame(last_12_posts)\n",
    "\n",
    "\n",
    "    # Changing list type to str as sqlite3 doesn't accept this type\n",
    "    list_features = ['bio_links', 'biography_with_entities_entities', 'edge_mutual_followed_by_edges', 'pronouns']\n",
    "    for column in list_features: \n",
    "        if column in df_current_user.columns:\n",
    "            df_current_user[column] = df_current_user[column].apply(lambda x:  \"_LIST_SEPARATOR_\".join(x))\n",
    "\n",
    "    return df_current_user, df_last_12_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query post_id not in comments table \n",
    "query = \"\"\"\n",
    "SELECT  \n",
    "    DISTINCT\n",
    "    username\n",
    "FROM comments \n",
    "WHERE 1=1\n",
    "    AND username NOT IN (SELECT username FROM users)\n",
    "\"\"\"\n",
    "\n",
    "# Loading usernames to scrape from db\n",
    "usernames_to_scrape = pd.read_sql_query(query, con)[\"username\"]\n",
    "print(f\"Usernames to scrape: {len(usernames_to_scrape)}\")\n",
    "\n",
    "\n",
    "for index, username in enumerate(tqdm(usernames_to_scrape[:5])): \n",
    "    fetch_user_data(username)\n",
    "    \n",
    "    try:\n",
    "        df_current_user, df_current_last_12_posts = convert_json(username)\n",
    "    except FileNotFoundError: # If an error happened while fetching the data, no file\n",
    "        continue\n",
    "\n",
    "    # Not all users have the same numbaer of columns returned and SQL needs same cols to use 'append'\n",
    "    df_users = pd.read_sql_query('select * from users', con)\n",
    "    df_users = pd.concat([df_users, df_current_user]).drop_duplicates()\n",
    "    df_users.to_sql(\"users\", con, if_exists=\"replace\", index=False)\n",
    "    df_current_last_12_posts.to_sql(\"last_12_posts\", con, if_exists=\"append\", index=False)\n",
    "\n",
    "    # Profile pic\n",
    "    for username, profile_pic_url in df_current_user[[\"username\",  \"profile_pic_url\"]].values: \n",
    "        try:\n",
    "            urllib.request.urlretrieve(profile_pic_url, f\"data/photos/user_profile_pictures/{username}_pp_user_photo.png\")\n",
    "        except Exception as e:\n",
    "            print(username, e, end='\\r')\n",
    "\n",
    "    # Last 12 posts\n",
    "    df_current_last_12_posts = df_current_last_12_posts.reset_index()\n",
    "    for username, display_url, index in df_current_last_12_posts[[\"username\", \"display_url\", \"index\"]].values: \n",
    "        urllib.request.urlretrieve(display_url, f\"data/photos/user_last_12_posts/{username}_{index}_user_photo.png\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Screenshot bio url landing page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query users having a link and remove those with NA\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    DISTINCT \n",
    "    username\n",
    "    , external_url \n",
    "FROM users \n",
    "WHERE external_url IS NOT NULL\"\"\"\n",
    "\n",
    "df_user_urls = pd.read_sql_query(query, con)\n",
    "df_user_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Browser(\"chrome\")\n",
    "for username, external_url in tqdm(df_user_urls.values):\n",
    "    try:\n",
    "        browser.visit(external_url)\n",
    "        browser.driver.save_screenshot(f\"data/url_screenshot/{username}_external_url_screenshot.png\")\n",
    "        browser = mw.launch_driver(\"/Users/marclamy/Desktop/main file/code/igbot_final/chromedriver\")\n",
    "    except:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Giving cooler names to the users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coolname import generate_slug\n",
    "\n",
    "# Loading all dfs and creating a list of it\n",
    "df_comments = pd.read_sql_query('select * from comments', con)\n",
    "df_users = pd.read_sql_query('select * from users', con)\n",
    "df_last_12_posts = pd.read_sql_query('select * from last_12_posts', con)\n",
    "all_dfs = [df_comments, df_users, df_last_12_posts]\n",
    "\n",
    "# List all usernames\n",
    "all_usernames = [username for df in all_dfs for username in df['username']]\n",
    "print(len(all_usernames))\n",
    "all_usernames = list(set(all_usernames))\n",
    "print(len(all_usernames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from comments', con)[['username']]['username'].map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users['username'].head(10), df_comments['username'].head(10), df_last_12_posts['username'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_12_posts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "06d12861cad82bdcdde1b56bd9eda52e91f7df29dabbeda8f3d9112222750302"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
