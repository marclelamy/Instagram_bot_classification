{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. File description \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import module and setting notebook preferences\n",
    "\n",
    "### 0.1 Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 10 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import src.useful as su\n",
    "import src.labelling as sl\n",
    "import src.image as si\n",
    "import src.model as sm \n",
    "import src.webscraping as sw\n",
    "import src.viz as sv\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "import dtale\n",
    "# from autoviz import data_cleaning_suggestions\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import re\n",
    "import os\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize()\n",
    "sl.Mypandas.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Notebook preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting pandas options\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.float_format = '{:,}'.format\n",
    "\n",
    "# Setting plotly as dark\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "plotly_kwargs = {'category_orders': {\"label\": [0, 1, 2, 3]},\n",
    "                 'color_discrete_sequence': ['#1f77b4', '#EF553B', '#00CC96', '#FECB52']}\n",
    "\n",
    "# Creating SQL database to store all the data for the project\n",
    "database = \"data/main_database.sqlite\"\n",
    "con = sqlite3.connect(database)\n",
    "\n",
    "# Setting path to export viz\n",
    "viz_dir = '/Users/marclamy/Desktop/code/viz/instabot/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Load and consolidate the data into a single table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = sl.load_main()\n",
    "df_labels = sl.load_labels()\n",
    " \n",
    "df_main = df_main.merge(df_labels, how='left', on='username')\n",
    "\n",
    "# either fillna, either dropna, depending on the use case, comment/uncomment\n",
    "# df_main['label'] = df_main['label'].fillna(-1).astype(int)\n",
    "# df_main['label'] = df_main['label'].astype(str)\n",
    "\n",
    "df_main = df_main.dropna(subset='label').reset_index(drop=True)\n",
    "df_main['label'] = df_main['label'].astype(int)\n",
    "df_main['binary_label'] = df_main['label'].apply(lambda x: 1 if x == 3 else x).astype(int)\n",
    "\n",
    "# df_main = sl.Mypandas(df_main)\n",
    "\n",
    "\n",
    "df_main = df_main.drop([col for col in df_main.columns if any([f'posts_{x}' in col for x in ['sum', 'min', 'max', 'avg', 'concat']])], axis=1)\n",
    "\n",
    "\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('say \"error\"')\n",
    "# asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serie = [x for x in enumerate(range(df_main['follow_count'].min() // 100, df_main['follow_count'].max() // 100))]\n",
    "# serie =\n",
    "\n",
    "# for value in range()\n",
    "\n",
    "# serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4 Counting labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_comments = df_main.shape[0]\n",
    "unique_usernames = df_main.drop_duplicates(subset='username').shape[0]\n",
    "\n",
    "labels = df_main['label'].value_counts()\n",
    "labels_unique = df_main.drop_duplicates(subset='username')['label'].value_counts()\n",
    "\n",
    "\n",
    "print(f'{unique_comments = }')\n",
    "print(f'{unique_usernames = }\\n')\n",
    "print(f'Labels for comment \\n{labels}\\n')\n",
    "print(f'Labels unique users \\n{labels_unique}\\n\\n')\n",
    "print(f'% comments labelled: {sum(labels)/unique_comments:.1%}')\n",
    "print(f'% users labelled: {sum(labels_unique)/unique_usernames:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Quick viz - Move this to part 2 for when the data is clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.X Pandas profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate report of the data\n",
    "# profile = ProfileReport(df_main, title=\"Pandas Profiling Report\")\n",
    "# profile.to_file('data/pandas_profiling.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.X dtale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtale.show(df_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.x Autoviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('say \"auto viz done\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Data cleaning and Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following: \n",
    "* Clean the column \n",
    "    * Remove missing value/add a missing flag column\n",
    "    * Flag and remove outliers\n",
    "* Add new features\n",
    "* Data viz\n",
    "    * Look at the distribution for each label\n",
    "    * Look at describe per label \n",
    "    * Next to the title, add - Done / - missing markdown\n",
    "---\n",
    "\n",
    "\n",
    "Sub groups of 1.0 with: \n",
    "* Biography \n",
    "    * bio/bio wo emoji \n",
    "    * bio emoji count \n",
    "* Comment \n",
    "    * Comment/wo emoji\n",
    "    * Comment int cols \n",
    "* Follow/er count \n",
    "* Domain\n",
    "* Post/video count \n",
    "    * and highlight_reel_count\n",
    "* Binary\n",
    "    * hide like and view count \n",
    "    * has guides \n",
    "    * has clips \n",
    "    * is private \n",
    "    * is embeds \n",
    "    * is joined \n",
    "    * is verified\n",
    "* Professional/business account \n",
    "* Posts list\n",
    "* Dates diff \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['outlier'] = ''\n",
    "def print_outliers(df, col, threshold=None):\n",
    "    '''Calculating outliers and flagging them'''\n",
    "    lower_bound, upper_bound = df.outliers_bound(col)\n",
    "    df['outlier'] = df.apply(lambda x: x['outlier'] if lower_bound < x[col] < upper_bound else x['outlier'] + ', ' + col, axis=1)\n",
    "    print(f'Lower bound: {lower_bound} - Upper bound: {upper_bound}\\n')\n",
    "    print(df.query(f'{col} >= @upper_bound').shape[0], 'outliers found\\n')\n",
    "\n",
    "    # Checking outliers per label \n",
    "    for label in (0, 1, 3):\n",
    "        print(f'Label: {label}')\n",
    "        display(df.query(f'label == {label}')[col].apply(lambda x: lower_bound <= x <= upper_bound).value_counts().reset_index().rename(columns={'index': 'Condition', col: 'Count'}).assign(Percentage=lambda x: (x['Count']/x['Count'].sum()*100).round(1)))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Comments - Done âœ…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.0 Gram functions\n",
    "\n",
    "Creating functions to clean/calculate/show different grams of the comments. Will be reusing them for biography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_tokenize(biographies):\n",
    "    \"\"\"\n",
    "    Given a list of biographies, this function performs the following steps:\n",
    "    1. Remove unwanted characters from each biography\n",
    "    2. Tokenize the cleaned text into words\n",
    "    3. Remove stop words from the tokenized text\n",
    "    4. Return the filtered list of tokens\n",
    "\n",
    "    Parameters:\n",
    "    biographies (list): List of strings representing the biographies\n",
    "\n",
    "    Returns:\n",
    "    filtered (list): List of lists of filtered tokens\n",
    "    \"\"\"\n",
    "    # Remove unwanted characters\n",
    "    cleaned = [re.sub(r'[^\\w\\s\\d]', '', b).lower() for b in biographies]\n",
    "    # Tokenize the text\n",
    "    tokenized = [nltk.tokenize.word_tokenize(b) for b in cleaned]\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered = [[w for w in t if w.lower() not in stop_words or w.isdigit()] for t in tokenized]\n",
    "    return filtered\n",
    "    \n",
    "\n",
    "def most_frequent_grams(tokens, grams):\n",
    "    bigrams = [', '.join(b) for t in tokens for b in list(nltk.ngrams(t, grams))]\n",
    "    most_frequent = dict(Counter(bigrams))\n",
    "    return most_frequent\n",
    "\n",
    "\n",
    "def calculate_grams(df, column, max_gram_degree):\n",
    "    df_grams = pd.DataFrame(columns=['gram', 'count', 'label', 'gram_degree'])\n",
    "    for label in (0, 1, 2, 3):\n",
    "        tokens = clean_and_tokenize(df.query(f'label == {label}')[column])\n",
    "        for gram in (1, 2, 3, 4):\n",
    "            top_tokens = most_frequent_grams(tokens, gram)\n",
    "            # top_tokens = {i:[j] for i, j in top_tokens.items()}\n",
    "            # df_top_tokens = pd.DataFrame(top_tokens, columns=[f'label_{label}_gram_{gram}', f'label_{label}_count_{gram}'])\n",
    "            current_df = pd.DataFrame(top_tokens.items(), columns=['gram', 'count'])\n",
    "            current_df['gram_degree'] = gram\n",
    "            current_df['label'] = label\n",
    "            df_grams = pd.concat([df_grams, current_df], axis=0)\n",
    "    return df_grams\n",
    "\n",
    "\n",
    "def keep_top_n_grams(df, n):\n",
    "    df_grams_grouped = df.query('label in (0, 1, 3)').sort_values(by=['label', 'gram_degree', 'count'], ascending=[True, True, False])\n",
    "    df_grams_grouped['row_number'] = df_grams_grouped.groupby(['label', 'gram_degree']).cumcount() + 1\n",
    "    grams_to_keep = df_grams_grouped.query('row_number <= @n')['gram'].unique().tolist()\n",
    "    df = df.query('gram in @grams_to_keep').sort_values(['label', 'gram_degree', 'count'], ascending=[True, True, False])\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def plot_grams(df): \n",
    "    for degree in df.gram_degree.unique(): \n",
    "        fig = px.bar(\n",
    "            df.query('gram_degree == @degree'), \n",
    "            x='gram', \n",
    "            y='count', \n",
    "            color='label', \n",
    "            # barmode='group', \n",
    "            **plotly_kwargs,\n",
    "            title=f'Most grams by label and degree {degree}')\n",
    "        fig.update_xaxes(tickangle=-90)\n",
    "        # fig.update_layout(xaxis={'categoryorder':'total descending'})\n",
    "        \n",
    "        display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Wordcloud\n",
    "\n",
    "* ????????????????????               Both legit and other bots have the word \"first\", but not for the same reason. For the legits, its only to be first to comment where for the bots it's the first who read out to them. Let's check the average sentence length where first is in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot wordcloud\n",
    "# for label in (0, 1, 3):\n",
    "#     print(f'Label: {label}')\n",
    "#     wordcloud = WordCloud(width=1800, \n",
    "#                           height=1200, \n",
    "#                           min_font_size=1, \n",
    "#                           max_words=500, \n",
    "#                           colormap='tab10')\n",
    "                          \n",
    "#     word_list = ' '.join([word for list in df_main.query(f'label == {label}')['comment_wo_emoji'].str.split(' ') for word in list])\n",
    "#     wordcloud.generate(word_list)\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.savefig(f'{viz_dir}/wordcloud_comment_{label}.png', dpi=300, pad_inches=0.0, bbox_inches='tight')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Calculating bi/tri/quad grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df_main.loc[:, ['comment_wo_emoji', 'label']].drop_duplicates()\n",
    "df_bio_grams = calculate_grams(sub_df, 'comment_wo_emoji', 20)\n",
    "df_bio_grams = keep_top_n_grams(df_bio_grams, 30)\n",
    "plot_grams(df_bio_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Feature engineering\n",
    "For each comment, count how many of the top 30 grams to they have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding tri/quad grams count to main df\n",
    "bots_triquadgrams = df_bio_grams.query('label > 0 and gram_degree > 2').gram.unique().tolist()\n",
    "\n",
    "def count_grams(text, grams):\n",
    "    count = 0\n",
    "    for gram in grams:\n",
    "        gram = gram.split(',')\n",
    "        if all(word in text for word in gram):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "df_main['comment_grams_count'] = df_main['comment_wo_emoji'].apply(lambda x: count_grams(x, bots_triquadgrams))\n",
    "\n",
    "print('% of each label having at least one tri/quad gram')\n",
    "for label in (0, 1, 3): \n",
    "    current_df = df_main.query(f'label == {label}')['comment_grams_count'] > 0\n",
    "    current_df = current_df.value_counts(normalize=True)\n",
    "    display(current_df.to_frame(name=f'Label: {label}').round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding comment length and word count\n",
    "df_main['comment_length'] = df_main['comment'].str.len()\n",
    "df_main['comment_word_count'] = df_main['comment'].str.count(' ') + 1\n",
    "\n",
    "# Dropping columns\n",
    "df_main = df_main.drop(columns=['comment', 'comment_wo_emoji', 'comment_emoji'])\n",
    "df_main.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Comment likes and time difference - 90% done, missing the insights of last chart\n",
    "\n",
    "There are multiple other columns about the comments of the users. \n",
    "* `comments_likes`: the number of likes received by the bots. I suspect them to be inflated by many as found some bots with more than 200 likes seconds after the post was posted. This data is mainly produced by bots (they like themselves and other bots like their comment) but legit users like you and me could also like the comment. \n",
    "* `comment_time_difference`: number of seconds between post being publish and the comment of the bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['comments_likes', 'comment_time_difference']\n",
    "\n",
    "print('Missing values: ')\n",
    "df_main[cols].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Comments Likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.describe_column_by_colcat('comments_likes')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating outliers and flagging them\n",
    "lower, upper = df_main.outliers_bound('comments_likes')\n",
    "df_main['outlier'] = df_main['comments_likes'].apply(lambda x: '' if lower < x < upper else 'comments_likes')\n",
    "lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biography length distribution\n",
    "fig = px.histogram(\n",
    "    df_main.query('outlier == \"\"'),\n",
    "    x='comments_likes', \n",
    "    nbins=200,\n",
    "    color=\"label\",\n",
    "    opacity=.7,\n",
    "    marginal=\"box\", # or violin, rug)\n",
    "    title=f'Distribution of Biography Length per Label for users with biographies',\n",
    "    **plotly_kwargs\n",
    "    )\n",
    "\n",
    "fig = fig.update_layout(barmode='overlay')\n",
    "\n",
    "# sv.save_plotly_fig(fig)\n",
    "sv.save_plotly_fig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_main.query('label == 3')['comments_likes'] > 0).value_counts(normalize=True).multiply(100).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a very clear distinction between the distribution of the likes on the comments. \n",
    "* Other bots have almost no likes on their comments. Their Q3 is at 0 and avg at 11 with only 10% of them having at least a like.\n",
    "* The bots definitely have a weird distribution. It's kinda like waves and they don't have anything between 300 and 500 but then have a bump, this is sus.\n",
    "* Legit users have what seems to be a very skewed but guessable distribution. The more the likes, the less the people have them.\n",
    "\n",
    "It'll be interesting to see how that that correlates with time difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Comment Time Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.describe_column_by_colcat('comment_time_difference')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating outliers and flagging them\n",
    "lower, upper = df_main.outliers_bound('comment_time_difference')\n",
    "df_main['outlier'] = df_main['comment_time_difference'].apply(lambda x: '' if lower < x < upper else 'comment_time_difference')\n",
    "lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biography length distribution\n",
    "fig = px.histogram(\n",
    "    df_main.query('outlier == \"\"'),\n",
    "    x='comment_time_difference', \n",
    "    nbins=200,\n",
    "    color=\"label\",\n",
    "    opacity=.7,\n",
    "    marginal=\"box\", # or violin, rug\n",
    "    title=f'Distribution of Comment Time Difference per Label<br><sub>Comment time difference is the time difference between the comment and the post in seconds',\n",
    "    **plotly_kwargs\n",
    "    )\n",
    "\n",
    "fig = fig.update_layout(barmode='overlay')\n",
    "fig  = fig.add_vline(x=0, line_color=\"green\", line_width=2, annotation_text=\"0\")\n",
    "\n",
    "# sv.save_plotly_fig(fig)\n",
    "sv.save_plotly_fig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_main.query('label == 3')['comments_likes'] > 0).value_counts(normalize=True).multiply(100).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before, there is a clear distinction between the three distribution: \n",
    "* Bots are way more skewed towards 0 with most commenting under 70seconds\n",
    "* legit users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main[[col for col in df_main if 'com' in col and 'post' not in col]].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Biography - 90% done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Nulls: {df_main.biography.isna().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.biography.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 biography wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot wordcloud\n",
    "# for label in (0, 1, 3):\n",
    "#     print(f'Label: {label}')\n",
    "#     wordcloud = WordCloud(width=1800, \n",
    "#                           height=1200, \n",
    "#                           min_font_size=1, \n",
    "#                           max_words=500, \n",
    "#                           colormap='tab10')\n",
    "                          \n",
    "#     word_list = ' '.join([word for list in df_main.query(f'label == {label}')['biography_wo_emoji'].str.split(' ') for word in list])\n",
    "#     wordcloud.generate(word_list)\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.savefig(f'{viz_dir}/wordcloud_biography_{label}.png', dpi=300, pad_inches=0.0, bbox_inches='tight')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Calculating bi/tri/quad grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df_main.loc[:, ['biography_wo_emoji', 'label']].drop_duplicates()\n",
    "df_bio_grams = calculate_grams(sub_df, 'biography_wo_emoji', 20)\n",
    "df_bio_grams = keep_top_n_grams(df_bio_grams, 30)\n",
    "plot_grams(df_bio_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 Feature engineering\n",
    "For each biography, count how many of the top30 grams to they have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding tri/quad grams count to main df\n",
    "bots_triquadgrams = df_bio_grams.query('label > 0 and gram_degree > 2').gram.unique().tolist()\n",
    "\n",
    "def count_grams(text, grams):\n",
    "    count = 0\n",
    "    for gram in grams:\n",
    "        gram = gram.split(',')\n",
    "        if all(word in text for word in gram):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "df_main['biography_grams_count'] = df_main.biography_wo_emoji.apply(lambda x: count_grams(x, bots_triquadgrams))\n",
    "\n",
    "print('% of each label having at least one tri/quad gram')\n",
    "for label in (0, 1, 3): \n",
    "    current_df = df_main.query(f'label == {label}')['biography_grams_count'] > 0\n",
    "    current_df = current_df.value_counts(normalize=True)\n",
    "    display(current_df.to_frame(name=f'Label: {label}').round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding comment length and word count\n",
    "df_main['biography_length'] = df_main['biography'].str.len()\n",
    "df_main['biography_word_count'] = df_main['biography'].str.count(' ') + 1\n",
    "df_main['biography_linebreak_count'] = df_main['biography'].str.count('\\n')\n",
    "\n",
    "# Dropping columns\n",
    "df_main = df_main.drop(columns=['biography', 'biography_wo_emoji', 'biography_emoji'])\n",
    "df_main.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biography length distribution\n",
    "sub_df = df_main.query('biography_length > 0')\n",
    "fig = px.histogram(\n",
    "    sub_df,\n",
    "    x='biography_length', \n",
    "    nbins=50,\n",
    "    color=\"label\",\n",
    "    opacity=.7,\n",
    "    marginal=\"box\", # or violin, rug)\n",
    "    title=f'Distribution of Biography Length per Label for users with biographies',\n",
    "    **plotly_kwargs\n",
    "    )\n",
    "\n",
    "fig = fig.update_layout(barmode='overlay')\n",
    "\n",
    "# sv.save_plotly_fig(fig)\n",
    "sv.save_plotly_fig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the users having a biography:\n",
    "* Legit users tend to have a shorter biography with 50% less than 48 characters. Their IQR is 77 and they occupy all bounds of the distribution. \n",
    "* Bots have half of their bio between 55 nd 81 characters (IQR) and generally dont use less than 20 characters or more than 120 \n",
    "* The other type of bot, also has its own distribution with 75% of their bio having more than 120 characters. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Follow & Follower Count - Missing insights (markdown)\n",
    "\n",
    "The columns follow and follower count are the number of people following and being followed by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_columns = ['follow_count', 'follower_count']\n",
    "for col in current_columns: \n",
    "    print(f'Missing values {col}: {df_main[col].isna().sum()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Follow Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_describe, fig = df_main.describe_column_by_colcat('follow_count')\n",
    "\n",
    "display(df_describe)\n",
    "fig.update_layout(yaxis_range=[0, 2300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = print_outliers(df_main, 'follow_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_main,#.query('outlier.str.contains(\"follow_count\") == False'),\n",
    "                   x=\"follow_count\", \n",
    "                   nbins=500,\n",
    "                   color=\"label\",\n",
    "                   opacity=.7,\n",
    "                   marginal=\"box\", # or violin, rug)\n",
    "                   title='Distribution of the follow count per label',\n",
    "                   **plotly_kwargs\n",
    "                   )\n",
    "\n",
    "\n",
    "fig = fig.update_layout(barmode='overlay')\n",
    "\n",
    "# sv.save_plotly_fig(fig)\n",
    "sv.save_plotly_fig(fig, 'fig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the follow count is very interesting. All labels' interquartile range (between Q1 and Q3) occupy the 0-2.5k follow count range. the main category of bots (sex bots, main obj of the project) tend to follow between 0 and 243 accounts. from 240 to 1,030 there are the legit users and from 1100 to 2.2k, the other type of bot. \n",
    "\n",
    "\n",
    "The bots (1) tend to be more about mass commenting, that's how they scam people\n",
    "The legit user have a larger distribution and are more diverse\n",
    "The other type of bot have a higher distribution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Follower count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing column for each label\n",
    "sub_df, fig = df_main.describe_column_by_colcat('follower_count')\n",
    "\n",
    "print('Follower count: ')\n",
    "display(sub_df.style.format('{:,}'))\n",
    "# sv.save_plotly_fig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers\n",
    "df_main = print_outliers(df_main, 'follower_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the bots at 6k max follower and other bots at 14k, I can assume that none, even if not labelled yet, can have more than 30k followers to be large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting follower count distribution\n",
    "fig = px.histogram(df_main.query('follower_count < 20000'), \n",
    "                   x=\"follower_count\", \n",
    "                   nbins=200,\n",
    "                   color=\"label\",\n",
    "                   opacity=.7,\n",
    "                   marginal=\"box\", # or violin, rug\n",
    "                   title='Distribution of the follower count per label.<br><sub>Numbers next to lines are the quantiles.',\n",
    "                   **plotly_kwargs\n",
    "                   )\n",
    "\n",
    "# max_follower_bot = df_main.query('label > 0')['follower_count'].max() * 2\n",
    "\n",
    "fig = fig.update_layout(barmode='overlay')\n",
    "\n",
    "sv.save_plotly_fig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 Feature engineering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Posts, videos and highlight count - Mostly done, missing insights\n",
    "\n",
    "Those three columns are about the content of the users, counting the posts (photos and videos), videos and highlight reel (old stories showing on profile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_columns = ['post_count', 'video_count', 'highlight_reel_count']\n",
    "for col in current_columns: \n",
    "    print(f'Missing values {col}: {df_main[col].isna().sum()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.1 Post count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing column for each label\n",
    "sub_df, fig = df_main.describe_column_by_colcat('post_count')\n",
    "\n",
    "print('Post count described by label: ')\n",
    "display(sub_df.style.format('{:,}'))\n",
    "# sv.save_plotly_fig(fig, 'fig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = print_outliers(df_main, 'post_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the outliers are for the legit users, there's only a small percentage of the bots being outliers compared to the legit users. This is due as the bots need some photos to make people believe they have an account but generally have the same numbers of posts, once they posted their photos they are good. Legit users is the group having the most outliers as people normally have one single acccount where they post photos over the years and more frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.histogram(df_main.query('post_count < 5000'), \n",
    "                   x=\"post_count\", \n",
    "                   nbins=5000,\n",
    "                   color=\"label\",\n",
    "                   opacity=.8,\n",
    "                   marginal=\"box\", # or violin, rug\n",
    "                   title='Distribution of the post count per label.',\n",
    "                   **plotly_kwargs\n",
    "                   )\n",
    "\n",
    "\n",
    "fig = fig.update_layout(barmode='overlay', xaxis_range=(0, 100)) # Default range is 0, 100 but can be changed to max by double clicking on plolty viz\n",
    "\n",
    "sv.save_plotly_fig(fig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.2 Video Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing column for each label\n",
    "sub_df, fig = df_main.describe_column_by_colcat('video_count')\n",
    "\n",
    "print('Post count described by label: ')\n",
    "display(sub_df.style.format('{:,}'))\n",
    "# sv.save_plotly_fig(fig, 'fig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = print_outliers(df_main, 'video_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_main.query('video_count < 1000'), \n",
    "                   x=\"video_count\", \n",
    "                   nbins=1000,\n",
    "                   color=\"label\",\n",
    "                   opacity=.8,\n",
    "                   marginal=\"box\", # or violin, rug\n",
    "                   title='Distribution of the video count per label (max 1000)',\n",
    "                   **plotly_kwargs\n",
    "                   )\n",
    "\n",
    "\n",
    "fig = fig.update_layout(barmode='overlay', xaxis_range=(0, 100)) # Default range is 0, 100 but can be changed to max by double clicking on plolty viz\n",
    "\n",
    "sv.save_plotly_fig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, most of the users have 0 video. The legit users have a very skewed distribution with a lot of outliers. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.3 Highlight Reel Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing column for each label\n",
    "sub_df, fig = df_main.describe_column_by_colcat('highlight_reel_count')\n",
    "\n",
    "print('Post count described by label: ')\n",
    "display(sub_df.style.format('{:,}'))\n",
    "sv.save_plotly_fig(fig, 'fig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = print_outliers(df_main, 'highlight_reel_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.histogram(df_main.query('highlight_reel_count < 1000'), \n",
    "                   x=\"highlight_reel_count\", \n",
    "                   nbins=1000,\n",
    "                   color=\"label\",\n",
    "                   opacity=.8,\n",
    "                   marginal=\"box\", # or violin, rug\n",
    "                   title='Distribution of the highlight reel count per label',\n",
    "                   **plotly_kwargs\n",
    "                   )\n",
    "\n",
    "\n",
    "fig = fig.update_layout(barmode='overlay', xaxis_range=(0, 100)) # Default range is 0, 100 but can be changed to max by double clicking on plolty viz\n",
    "\n",
    "sv.save_plotly_fig(fig, 'fig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5): \n",
    "    p = df_main.query(f'highlight_reel_count >= {i} and label == 3').shape[0] / df_main.query(f'label == 3').shape[0]\n",
    "    print(f'{p:.0%} of the bots have {i} or more highlight reels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other tye of bot has its distribution quite different from both other groups. 80% of the other bots have highlight reels, quite an important feature for them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Pronouns - Done âœ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "for label in (0, 1, 3): \n",
    "    sub_df = df_main.query(f\"label == {label}\")\n",
    "    p = sub_df['pronouns'].isna().sum() / sub_df.shape[0] * 100\n",
    "    print(f'Label: {label} - % of users with pronouns: {p:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the users having a pronoun are legit users and but some bots have it too. There are a ton of missing values (>98%) so I'll just create a flag for originally missing/not missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['pronouns_na_flag'] = df_main['pronouns'].isna().astype(int)\n",
    "df_main.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Domain - 50% done\n",
    "\n",
    "The domain column is the domain url that the users had in their bio bu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_count = df_main['domain'].isna().sum()\n",
    "print(f\"The domain column has {na_count:,} ({na_count / df_main.shape[0]:.1%}) missing values (no link in bio).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df_main.copy(deep=True)\n",
    "sub_df['domain'] = sub_df['domain'].fillna('None')\n",
    "\n",
    "\n",
    "df_domain_label_count = sub_df.groupby(['domain', 'label'], as_index=False).agg({'username': 'count'}).rename({'username': 'count'}, axis=1).sort_values('count', ascending=False)\n",
    "df_domain_count = sub_df.groupby('domain', as_index=False).agg({'username': 'count'}).rename({'username': 'domain_count'}, axis=1)\n",
    "sub_df = df_domain_label_count.merge(df_domain_count, on='domain', how='left')\n",
    "\n",
    "sub_df['count_p'] = sub_df['count'] / sub_df['domain_count']\n",
    "sub_df = sub_df.sort_values(['domain_count', 'count_p'], ascending=[True, False])\n",
    "\n",
    "px.bar(sub_df.query('domain_count > 500'), \n",
    "    x='count_p', \n",
    "    y='domain', \n",
    "    barmode='stack', \n",
    "    color='label', \n",
    "    **plotly_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.query('domain_count > 500')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7.x adding new columns based on if the website contains words from a list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Business/Verified - Done âœ…\n",
    "\n",
    "There are multiple columns like: `is_business_account`, `is_professional_account`, `category_enum`, `category_name`, `business_category_name`, `business_contact_method`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_columns = ['is_business_account', 'is_professional_account', 'category_enum', 'category_name', 'business_category_name', 'business_contact_method']\n",
    "\n",
    "sub_df = df_main[business_columns + ['label']]\n",
    "\n",
    "for col in business_columns: \n",
    "    col_na = sub_df[col].isna()\n",
    "    if col_na.sum() != 0:\n",
    "        sub_df[col] = sub_df[col].isna().astype(int)\n",
    "\n",
    "sub_df.groupby(business_columns, as_index=False)['label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business_groupby = df_main.groupby(['is_professional_account', 'is_business_account', 'label'], as_index=False)['username'].count()\n",
    "df_business_groupby['count_%'] = df_business_groupby['username'] / df_business_groupby['username'].sum()\n",
    "\n",
    "df_business_groupby.style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many bots are creating professional or business accounts. Seems like if you're a business, you're a professional but if you're pro, you're not necessarily a business. The highest combination is that most legit users and bots don't have a professional account. It's good to note that for the otherbots, there are as more accounts as professionals/business than normal accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.sunburst(df_main.dropna(subset='category_enum').fillna('na'),\n",
    "            path=['category_enum', 'category_name'],\n",
    "            color='label',\n",
    "            ).update_layout(uniformtext=dict(minsize=10, mode='hide'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_main, \n",
    "                    x='category_name', \n",
    "                    color='label',\n",
    "                    title=f'Distribution of labels for each category of category_name for bots and legit users')\n",
    "\n",
    "fig = fig.update_xaxes(tickangle=-90, categoryorder='total descending') \n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_main.query('label > 0'), \n",
    "                    x='category_name', \n",
    "                    color='label',\n",
    "                    title=f'Distribution of labels for each category of category_name for bots only')\n",
    "\n",
    "fig = fig.update_xaxes(tickangle=-90, categoryorder='total descending') \n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_main.query('label > 0'), \n",
    "                    x='business_category_name', \n",
    "                    color='label',\n",
    "                    title=f'Distribution of labels for each category of business_category_name for bots and legit users')\n",
    "\n",
    "fig = fig.update_xaxes(tickangle=-90, categoryorder='total descending') \n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting to see the difference between the bots and the sex bots. Even though many have been miss labelled (they'll both be marked at 1 when developping the model) bet ween bot or otherbot, there is a significative distinction between how they identify themselves.\n",
    "\n",
    "Other bots seems to be more entreupreuners, financial service or investment firm where bots are more video creator (you bet), personnal blog or gamer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.query('label > 0')['category_name'].value_counts().sort_values(ascending=True)[df_main.query('label > 0')['category_name'].value_counts().sort_values(ascending=True).lt(12)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only binary columns\n",
    "df_main = df_main.drop(['category_name', 'business_category_name', 'business_contact_method', 'category_enum', 'should_show_category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done but need to add above\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.cm\n",
    "# cmap = matplotlib.cm.get_cmap('Reds')\n",
    "def left_subtract(l1,l2):\n",
    "    lst = []\n",
    "    for i in l1:\n",
    "        if i not in l2:\n",
    "            lst.append(i)\n",
    "    return lst\n",
    "def data_suggestions(data):\n",
    "    \"\"\"\n",
    "    Modified by Ram Seshadri. Original idea for data suggestions module was a Kaggler.\n",
    "    Many thanks to: https://www.kaggle.com/code/itkin16/catboost-on-gpu-baseline\n",
    "    \"\"\"\n",
    "    maxx = []\n",
    "    minn = []\n",
    "    all_cols = list(data)\n",
    "    cat_cols1 = data.select_dtypes(include='object').columns.tolist()\n",
    "    cat_cols2 = data.select_dtypes(include='category').columns.tolist()\n",
    "    cat_cols = list(set(cat_cols1+cat_cols2))\n",
    "    ### The next line may look odd but due to different versions of pandas which\n",
    "    ### treat the definition of float differently, I am forced to use this. Don't change it.\n",
    "    num_cols = data.select_dtypes(include='float16').columns.tolist() + data.select_dtypes(\n",
    "                    include='float32').columns.tolist() + data.select_dtypes(include='float64').columns.tolist()\n",
    "    non_num_cols = left_subtract(all_cols, num_cols)\n",
    "    for i in data.columns:\n",
    "        if i not in cat_cols:\n",
    "            ### for float and integer, no need to calculate this ##\n",
    "            minn.append(0)\n",
    "        else:\n",
    "            minn.append(data[i].value_counts().min())\n",
    "    length = len(data)\n",
    "    nunik = data.nunique()\n",
    "    nulls = data.isna().sum()\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "         #'column': list(data),\n",
    "        'Nuniques': nunik,\n",
    "         'NuniquePercent': (100*(nunik/length)),\n",
    "         'dtype': data.dtypes,\n",
    "         'Nulls' : nulls,\n",
    "         'Nullpercent' : 100*(nulls/length),\n",
    "         'Value counts Min':minn\n",
    "        },\n",
    "        columns = ['Nuniques', 'dtype','Nulls','Nullpercent', 'NuniquePercent',\n",
    "                       'Value counts Min'])\n",
    "    newcol = 'Data cleaning improvement suggestions'\n",
    "    print('%s. Complete them before proceeding to ML modeling.' %newcol)\n",
    "    mixed_cols = [col for col in data.columns if len(data[col].apply(type).value_counts()) > 1]\n",
    "    df[newcol] = ''\n",
    "    df['first_comma'] = ''\n",
    "    if len(cat_cols) > 0:\n",
    "        mask0 = df['dtype'] == 'object'\n",
    "        mask1 = df['Value counts Min']/df['Nuniques'] <= 0.05\n",
    "        mask4 = df['dtype'] == 'category'\n",
    "        df.loc[mask0&mask1,newcol] += df.loc[mask0&mask1,'first_comma'] + 'combine rare categories'\n",
    "        df.loc[mask4&mask1,newcol] += df.loc[mask4&mask1,'first_comma'] + 'combine rare categories'\n",
    "        df.loc[mask0&mask1,'first_comma'] = ', '\n",
    "        df.loc[mask4&mask1,'first_comma'] = ', '\n",
    "    mask2 = df['Nulls'] > 0\n",
    "    df.loc[mask2,newcol] += df.loc[mask2,'first_comma'] + 'fill missing'\n",
    "    df.loc[mask2,'first_comma'] = \", \"\n",
    "    mask3 = df['Nuniques'] == 1\n",
    "    df.loc[mask3,newcol] += df.loc[mask3,'first_comma'] + 'invariant values: drop'\n",
    "    df.loc[mask3,'first_comma'] = \", \"\n",
    "    if len(non_num_cols) > 0:\n",
    "        for x in non_num_cols:\n",
    "            if df.loc[x, 'NuniquePercent'] == 100:\n",
    "                df.loc[x, newcol] += df.loc[x,'first_comma'] + 'possible ID column: drop'\n",
    "                df.loc[x,'first_comma'] = \", \"\n",
    "    mask5 = df['Nullpercent'] >= 90\n",
    "    df.loc[mask5,newcol] += df.loc[mask5,'first_comma'] + 'very high nulls percent: drop'\n",
    "    df.loc[mask5,'first_comma'] = \", \"\n",
    "    #### check for infinite values here #####\n",
    "    inf_cols1 = np.array(num_cols)[[(data.loc[(data[col] == np.inf)]).shape[0]>0 for col in num_cols]].tolist()\n",
    "    inf_cols2 = np.array(num_cols)[[(data.loc[(data[col] == -np.inf)]).shape[0]>0 for col in num_cols]].tolist()\n",
    "    inf_cols = list(set(inf_cols1+inf_cols2))\n",
    "    ### Check for infinite values in columns #####\n",
    "    if len(inf_cols) > 0:\n",
    "        for x in inf_cols:\n",
    "            df.loc[x,newcol] += df.loc[x,'first_comma'] + 'infinite values: drop'\n",
    "            df.loc[x,'first_comma'] = \", \"\n",
    "    #### Check for skewed float columns #######\n",
    "    skew_cols1 = np.array(num_cols)[[(np.abs(np.round(data[col].skew(), 1)) > 1\n",
    "                    ) & (np.abs(np.round(data[col].skew(), 1)) <= 5) for col in num_cols]].tolist()\n",
    "    skew_cols2 = np.array(num_cols)[[(np.abs(np.round(data[col].skew(), 1)) > 5) for col in num_cols]].tolist()\n",
    "    skew_cols = list(set(skew_cols1+skew_cols2))\n",
    "    ### Check for skewed values in columns #####\n",
    "    if len(skew_cols1) > 0:\n",
    "        for x in skew_cols1:\n",
    "            df.loc[x,newcol] += df.loc[x,'first_comma'] + 'skewed: cap or drop outliers'\n",
    "            df.loc[x,'first_comma'] = \", \"\n",
    "    if len(skew_cols2) > 0:\n",
    "        for x in skew_cols2:\n",
    "            df.loc[x,newcol] += df.loc[x,'first_comma'] + 'highly skewed: drop outliers or do box-cox transform'\n",
    "            df.loc[x,'first_comma'] = \", \"\n",
    "    ##### Do the same for mixed dtype columns - they must be fixed! ##\n",
    "    if len(mixed_cols) > 0:\n",
    "        for x in mixed_cols:\n",
    "            df.loc[x,newcol] += df.loc[x,'first_comma'] + 'fix mixed data types'\n",
    "            df.loc[x,'first_comma'] = \", \"\n",
    "    df.drop('first_comma', axis=1, inplace=True)\n",
    "    return df\n",
    "###################################################################################\n",
    "def data_cleaning_suggestions(df):\n",
    "    \"\"\"\n",
    "    This is a simple program to give data cleaning and improvement suggestions in class AV.\n",
    "    Make sure you send in a dataframe. Otherwise, this will give an error.\n",
    "    \"\"\"\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        dfx = data_suggestions(df)\n",
    "        all_rows = dfx.shape[0]\n",
    "        ax = dfx.head(all_rows).style.background_gradient()  \n",
    "        display(ax);\n",
    "    else:\n",
    "        print(\"Input must be a dataframe. Please check input and try again.\")\n",
    "###################################################################################\n",
    "\n",
    "\n",
    "# exclude_cols = ['username', 'biography', 'follow_count'] + [col for col in df_main.columns if isinstance(df_main.loc[0, col], (dict, list))]\n",
    "data_cleaning_suggestions(df_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.to_sql('main_after_univariate', con, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Above this is new clean code and markdown formatting where below is old code kinda eh formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('say \"done\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.x Comment time difference WHATS THE AVERAG DIFFERENCE BETWEEN EACH POST? COULD BE UPLOADED SUPER FAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def round_or_int(val, **kwargs): \n",
    "#     if pd.isna(val): \n",
    "#         return val\n",
    "#     elif val == int(val): \n",
    "#         return int(val) \n",
    "#     else:\n",
    "#         return round(val, ndigits=kwargs['ndigits'])\n",
    "\n",
    "# def calculate_posts_time_diff_btw_each(date_concat): \n",
    "#     if pd.isna(date_concat): \n",
    "#         return date_concat\n",
    "#     dates = [pd.to_datetime(date) for date in date_concat.split(',')]\n",
    "#     dates = sorted(list(set(dates)))[:12]\n",
    "#     dates_diff = pd.Series(dates).diff().dt.seconds.dropna().reset_index(drop=True)\n",
    "#     dates_diff_summary = dates_diff.describe().apply(round_or_int, ndigits=2).to_dict()\n",
    "#     dates_diff_summary.update({'dates_diff': dates_diff.tolist(),\n",
    "#                                'unique_values': len(set(dates_diff)),\n",
    "#                                'total_values': len(dates_diff)\n",
    "#                                })\n",
    "\n",
    "#     # display(pd.DataFrame({i:[j] for i, j in dates_diff_summary.items()}))\n",
    "#     dates_diff_summary = {'dates_diff_' + i:j for i, j in dates_diff_summary.items()}\n",
    "#     return dates_diff_summary\n",
    "\n",
    "# df_main['posts_diff_btw_each_summary_seconds'] = df_main['posts_concat_posted_time'].parallel_apply(calculate_posts_time_diff_btw_each)\n",
    "# # calculate_posts_time_diff_btw_each(df_main.loc[1, 'posts_concat_posted_time'])\n",
    "# df_posts_diff_btw_each_summary = pd.json_normalize(df_main['posts_diff_btw_each_summary_seconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_main = pd.concat([df_main, df_posts_diff_btw_each_summary], axis=1)\n",
    "# df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_df = df_main[['dates_diff_follows_pattern', 'post_count', 'label']]\n",
    "\n",
    "# fig = px.scatter_matrix(sub_df, color='label', title='Pairplot')\n",
    "# sv.save_plotly_fig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Describing column for each label\n",
    "# sub_df, fig = df_main.describe_column_by_label('dates_diff_50%')\n",
    "\n",
    "# print('dates_diff_50%: ')\n",
    "# display(sub_df.style.format('{:,}'))\n",
    "# fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column = 'comments_likes'\n",
    "# cols_co_keep = [column] + ['username', 'biography', 'label', 'labelling_technique', 'domain', 'comment']\n",
    "\n",
    "# sub_df = df_main.query('label > 0').sort_values(column, ascending=False)[cols_co_keep].drop_duplicates()\n",
    "# # display(df_main.head(50))\n",
    "# username = 'axiomatic-merciful-mayfly'\n",
    "# # print(sl.load_table('select '))\n",
    "# # print(username)\n",
    "\n",
    "# display(sl.load_labels(include_all=True).query('username == @username'))\n",
    "# # display(sl.load_table('username_mapping').query('cooler_name == @username'))\n",
    "# # df_main.query('username == @username')\n",
    "\n",
    "\n",
    "# # sub_df.query('comments_likes > 1000 and label > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_main.query('biography.str.contains(\"skate\") and label > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_main.query('username == \"axiomatic-merciful-mayfly\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done investigating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Multi variate analysis - Past this point the data is entirely clean and ready for ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_sql_query('select * from main_after_univariate', con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Removing columns for now as there are way too many and feel overwhelmed\n",
    "# cols_to_remove = ['posts_sum', 'posts_avg', 'posts_max', 'posts_min', 'posts_con', 'dates_dif']\n",
    "# cols_to_remove = [col for col in df_main.columns if any([x in col for x in cols_to_remove])] + ['biography', 'biography_wo_emoji', 'biography_emoji', 'domain', 'comment', 'comment_wo_emoji',\n",
    "#                                                                                                 'comment_emoji', 'labelling_technique', 'posts_diff_btw_each_summary_seconds']\n",
    "# cols_to_keep = [col for col in df_main.columns if col not in cols_to_remove]\n",
    "\n",
    "# df_main = df_main[cols_to_keep]\n",
    "# df_main.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Pair plot & correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = []\n",
    "# for x in ['username', 'biography_emoji_count', 'biography_emoji_count_distinct',\n",
    "#        'follow_count', 'follower_count', 'pronouns', 'domain',\n",
    "#        'comments_likes', 'comment_emoji_count', 'comment_emoji_count_distinct',\n",
    "#        'comment_time_difference', 'post_count', 'video_count',\n",
    "#        'highlight_reel_count', 'hide_like_and_view_counts', 'has_guides',\n",
    "#        'has_clips', 'is_private', 'is_embeds_disabled', 'is_joined_recently',\n",
    "#        'is_professional_account', 'is_business_account',\n",
    "#        'should_show_public_contacts', 'posts_days_diff', 'posts_hours_diff',\n",
    "#        'is_verified', 'label', 'labelling_technique', 'binary_label',\n",
    "#        'outlier', 'comment_grams_count', 'comment_length',\n",
    "#        'comment_word_count', 'biography_grams_count', 'biography_length',\n",
    "#        'biography_word_count', 'biography_linebreak_count',\n",
    "#        'pronouns_na_flag']: \n",
    "#     print(x + '\\t\\t\\t\\t\\t', end='\\r')\n",
    "#     if input() == 'y': \n",
    "#         a.append(x)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_matrix = df_main.corr()\n",
    "\n",
    "\n",
    "\n",
    "# fig = px.imshow(corr_matrix,\n",
    "#                 color_continuous_scale='RdBu',\n",
    "#                 labels=dict(x='Variable', y='Variable', color='Correlation'),\n",
    "#                 x=corr_matrix.columns,\n",
    "#                 y=corr_matrix.columns)\n",
    "# fig.update_layout(title='Correlation Matrix',\n",
    "#                   width=600, height=600,\n",
    "#                   margin=dict(l=40, r=40, b=40, t=40))\n",
    "# fig.update_traces(showscale=True)\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_main.outlier.value_counts()fig = px.imshow(corr_matrix,\n",
    "#                 color_continuous_scale='RdBu',\n",
    "#                 labels=dict(x='Variable', y='Variable', color='Correlation'),\n",
    "#                 x=corr_matrix.columns,\n",
    "#                 y=corr_matrix.columns)\n",
    "# fig.update_layout(title='Correlation Matrix',\n",
    "#                   width=600, height=600,\n",
    "#                   margin=dict(l=40, r=40, b=40, t=40),\n",
    "#                   paper_bgcolor='white')\n",
    "# fig.update_traces(showscale=True)\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_main[cols + ['label', 'outlier']].query('outlier == \"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cols = ['follow_count', 'follower_count', 'post_count', 'video_count', 'is_private', 'posts_hours_diff']\n",
    "# sns.pairplot(df_main[cols + ['label', 'outlier']].query('label > 0'), \n",
    "#              hue=\"label\", )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.x ChatGPT charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df_main, x='follow_count', y='follower_count', trendline='ols',\n",
    "                 title='Follower Count vs. Follow Count')\n",
    "fig.update_layout(xaxis_title='Follow Count', yaxis_title='Follower Count')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot (df_main, xcol, ycol):\n",
    "       labels = df_main['label'].unique()\n",
    "\n",
    "       # create a dictionary to map label to subplot index\n",
    "       label_subplot_dict = {label: i+1 for i, label in enumerate(labels)}\n",
    "\n",
    "       # create figure with 2 rows and 3 columns (top chart uses 3 columns)\n",
    "       fig = make_subplots(rows=2, cols=len(labels), \n",
    "                     specs=[[{'rowspan': 1, 'colspan': len(labels)}] + [None for _ in range(len(labels)-1)],\n",
    "                            [{'rowspan': 1, 'colspan': 1} for label in labels]],\n",
    "                     subplot_titles=['All Labels'] + [f'Label {label}' for label in labels],\n",
    "                     x_title=f'X: {xcol.title()}',\n",
    "                     y_title=f'Y: {ycol.title()}')\n",
    "\n",
    "       # Adding all data\n",
    "       if xcol != None and ycol != None:\n",
    "              fig.add_trace(go.Histogram(x=df_main[xcol], name='All Labels'), row=1, col=1)\n",
    "       elif xcol !=  None and ycol == None: \n",
    "              fig.add_trace(go.Scatter(x=df_main[xcol], y=df_main[ycol], \n",
    "                                   mode='markers', name='All Labels'), row=1, col=1)\n",
    "\n",
    "       # label subplots\n",
    "       for label in df_main['label'].unique():\n",
    "              label_df = df_main[df_main['label'] == label]\n",
    "              if isinstance(xcol, str) and isinstance(ycol, str):\n",
    "                     fig.add_trace(go.Scatter(\n",
    "                                                 x=label_df[xcol], \n",
    "                                                 y=label_df[ycol], \n",
    "                                                 mode='markers', \n",
    "                                                 name=label, \n",
    "                                                 marker_color= plotly_kwargs['color_discrete_sequence'][int(label)]), \n",
    "                                   row=2, col=label_subplot_dict[label])\n",
    "\n",
    "              elif xcol is not None and ycol is None:\n",
    "                     fig.add_trace(go.Histogram(x=label_df[xcol], name=label), row=2, col=label_subplot_dict[label])\n",
    "\n",
    "       fig.update_layout(height=800, title=f'Distribution of Labels by {xcol.title()} and {ycol.title()}')\n",
    "\n",
    "\n",
    "       return fig\n",
    "\n",
    "\n",
    "plot(df_main.query('label > -1'), 'follow_count', 'follower_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.outlier.str.contains('follow_count').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.print_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT3 \n",
    "\n",
    "# Followers vs Follow Count\n",
    "\n",
    "fig = px.scatter(df_main, x=\"follow_count\", y=\"follower_count\", color=\"label\", trendline=\"ols\")\n",
    "fig.update_layout(title_text=\"Followers vs Follow Count\",\n",
    "                  xaxis_title=\"Follow Count\",\n",
    "                  yaxis_title=\"Follower Count\")\n",
    "display(fig.show())\n",
    "\n",
    "# # Comment Emoji Count vs Comment Time Difference\n",
    "\n",
    "# fig = px.scatter(df_main, x=\"comment_time_difference\", y=\"comment_emoji_count\", color=\"label\", trendline=\"ols\")\n",
    "# fig.update_layout(title_text=\"Comment Emoji Count vs Comment Time Difference\",\n",
    "#                   xaxis_title=\"Comment Time Difference\",\n",
    "#                   yaxis_title=\"Comment Emoji Count\")\n",
    "# display(fig.show())\n",
    "\n",
    "# # Post Count vs Video Count\n",
    "\n",
    "# fig = px.scatter(df_main, x=\"post_count\", y=\"video_count\", color=\"label\", trendline=\"ols\")\n",
    "# fig.update_layout(title_text=\"Post Count vs Video Count\",\n",
    "#                   xaxis_title=\"Post Count\",\n",
    "#                   yaxis_title=\"Video Count\")\n",
    "# display(fig.show())\n",
    "\n",
    "# # Highlight Reel Count vs Has Guides\n",
    "\n",
    "# fig = px.scatter(df_main, x=\"has_guides\", y=\"highlight_reel_count\", color=\"label\", trendline=\"ols\")\n",
    "# fig.update_layout(title_text=\"Highlight Reel Count vs Has Guides\",\n",
    "#                   xaxis_title=\"Has Guides\",\n",
    "#                   yaxis_title=\"Highlight Reel Count\")\n",
    "# display(fig.show())\n",
    "\n",
    "# # Has Clips vs Is Private\n",
    "\n",
    "# fig = px.scatter(df_main, x=\"is_private\", y=\"has_clips\", color=\"label\", trendline=\"ols\")\n",
    "# fig.update_layout(title_text=\"Has Clips vs Is Private\",\n",
    "#                   xaxis_title=\"Is Private\",\n",
    "#                   yaxis_title=\"Has Clips\")\n",
    "# display(fig.show())\n",
    "\n",
    "# # Is Embeds Disabled vs Is Joined Recently\n",
    "\n",
    "# fig = px.scatter(df_main, x=\"is_joined_recently\", y=\"is_embeds_disabled\", color=\"label\", trendline=\"ols\")\n",
    "# fig.update_layout(title_text=\"Is Embeds Disabled vs Is Joined Recently\",\n",
    "#                   xaxis_title=\"Is Joined Recently\",\n",
    "#                   yaxis_title=\"Is Embeds Disabled\")\n",
    "# display(fig.show())\n",
    "\n",
    "# # Is Professional Account vs Is Business Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate Analysis\n",
    "\n",
    "## Follow Count vs Follower Count\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(df_main, x=\"follow_count\", y=\"follower_count\", color=\"label\")\n",
    "fig.update_traces(marker=dict(size=6))\n",
    "fig.update_layout(title=\"Follow Count vs Follower Count\")\n",
    "display(fig)\n",
    "\n",
    "## Comment Emoji Count vs Comment Time Difference\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(df_main, x=\"comment_emoji_count\", y=\"comment_time_difference\", color=\"label\")\n",
    "fig.update_traces(marker=dict(size=6))\n",
    "fig.update_layout(title=\"Comment Emoji Count vs Comment Time Difference\")\n",
    "display(fig)\n",
    "\n",
    "## Post Count vs Video Count\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(df_main, x=\"post_count\", y=\"video_count\", color=\"label\")\n",
    "fig.update_traces(marker=dict(size=6))\n",
    "fig.update_layout(title=\"Post Count vs Video Count\")\n",
    "display(fig)\n",
    "\n",
    "## Highlight Reel Count vs Has Guides\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(df_main, x=\"highlight_reel_count\", y=\"has_guides\", color=\"label\")\n",
    "fig.update_traces(marker=dict(size=6))\n",
    "fig.update_layout(title=\"Highlight Reel Count vs Has Guides\")\n",
    "display(fig)\n",
    "\n",
    "## Has Clips vs Is Private\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(df_main, x=\"has_clips\", y=\"is_private\", color=\"label\")\n",
    "fig.update_traces(marker=dict(size=6))\n",
    "fig.update_layout(title=\"Has Clips vs Is Private\")\n",
    "display(fig)\n",
    "\n",
    "## Is Embeds Disabled vs Is Joined Recently\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(df_main, x=\"is_embeds_disabled\", y=\"is_joined_recently\", color=\"label\")\n",
    "fig.update_traces(marker=dict(size=6))\n",
    "fig.update_layout(title=\"Is Embeds Disabled vs Is Joined Recently\")\n",
    "display(fig)\n",
    "\n",
    "## Is Professional Account vs Is Business Account\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(df_main, x=\"is_professional_account\", y=\"is_business_account\", color=\"label\")\n",
    "fig.update_traces(marker=dict(size=6))\n",
    "fig.update_layout(title=\"Is Professional Account vs Is Business Account\")\n",
    "display(fig)\n",
    "\n",
    "## Should Show Public Contacts vs Posts Days Difference\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(df_main, x=\"should_show_public_contacts\", y=\"posts_days_diff\", color=\"label\")\n",
    "fig.update_traces(marker=dict(size=6))\n",
    "fig.update_layout(title=\"Should Show Public Contacts vs Posts Days Difference\")\n",
    "display(fig)\n",
    "\n",
    "## Comment Grams Count vs Biography Word Count\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(df_main, x=\"comment_grams_count\", y=\"biography_word_count\", color=\"label\")\n",
    "fig.update_traces(marker=dict(size=6))\n",
    "fig.update_layout(title=\"Comment Grams Count vs Biography Word Count\")\n",
    "display(fig)\n",
    "\n",
    "# Multivariate Analysis\n",
    "\n",
    "## Follow Count, Follower Count, and Comment Emoji Count\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(df_main, x=\"follow_count\", y=\"follower_count\", z=\"comment_emoji_count\", color=\"label\")\n",
    "fig.update_traces(marker=dict(size=6))\n",
    "fig.update_layout(title=\"Follow Count, Follower Count, and Comment Emoji Count\")\n",
    "display(fig)\n",
    "\n",
    "## Post Count, Video Count, and Highlight Reel Count\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(df_main, x=\"post_count\", y=\"video_count\", z=\"highlight_reel_count\", color=\"label\")\n",
    "fig.update_traces(marker=dict(size=6))\n",
    "fig.update_layout(title=\"Post Count, Video Count, and Highlight Reel Count\")\n",
    "display(fig)\n",
    "\n",
    "## Has Clips, Is Private, and Is Embeds Disabled\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(df_main, x=\"has_clips\", y=\"is_private\", z=\"is_embeds_disabled\", color=\"label\")\n",
    "fig.update_traces(marker=dict(size=6))\n",
    "fig.update_layout(title=\"Has Clips, Is Private, and Is Embeds Disabled\")\n",
    "display(fig)\n",
    "\n",
    "## Is Professional Account, Is Business Account, and Should Show Public Contacts\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(df_main, x=\"is_professional_account\", y=\"is_business_account\", z=\"should_show_public_contacts\", color=\"label\")\n",
    "fig.update_traces(marker=dict(size=6))\n",
    "fig.update_layout(title=\"Is Professional Account, Is Business Account, and Should Show Public Contacts\")\n",
    "display(fig)\n",
    "\n",
    "## Posts Days Difference, Comment Grams Count, and Biography Word Count\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(df_main, x=\"posts_days_diff\", y=\"comment_grams_count\", z=\"biography_word_count\", color=\"label\")\n",
    "fig.update_traces(marker=dict(size=6))\n",
    "fig.update_layout(title=\"Posts Days Difference, Comment Grams Count, and Biography Word Count\")\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "biography_bins = np.arange(0, 101, 10)\n",
    "comment_bins = np.arange(0, 51, 5)\n",
    "\n",
    "biography_word_counts = df['biography_word_count']\n",
    "comment_word_counts = df['comment_word_count']\n",
    "\n",
    "H, xedges, yedges = np.histogram2d(biography_word_counts, comment_word_counts, bins=(biography_bins, comment_bins))\n",
    "\n",
    "fig = px.imshow(H, x=biography_bins, y=comment_bins, color_continuous_scale='RdBu',\n",
    "                labels=dict(x='Biography Word Count', y='Comment Word Count', color='Count'))\n",
    "fig.update_layout(title='Biography Word Count vs. Comment Word Count',\n",
    "                  xaxis_title='Biography Word Count', yaxis_title='Comment Word Count')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Follow count & follow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_main.query('comment_time_difference > 74 and label > 0').sort_values('comment_time_difference', ascending=False)[['username', \n",
    "#                                                                                                         'post_count', \n",
    "#                                                                                                         'comment_time_difference', \n",
    "#                                                                                                         'biography', \n",
    "#                                                                                                         'label', \n",
    "#                                                                                                         'labelling_technique']].head(40)\n",
    "\n",
    "px.scatter_3d(df_main,\n",
    "              x='follow_count',\n",
    "              y='follower_count',\n",
    "              z='label',\n",
    "              color='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.6 Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdfasdfsafasd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.x Comment likes vs comment time diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df_main.copy(deep=True)\n",
    "\n",
    "\n",
    "# sub_df[]\n",
    "\n",
    "fig = px.scatter(sub_df,\n",
    "           x='comment_time_difference', \n",
    "           y='comments_likes',\n",
    "           color='label')\n",
    "# you can be casual and nice to read but remember that the public is from an age of 21 to 100 years old. \n",
    "fig.update_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent99 = df_main['follower_count'].quantile(0.9)\n",
    "sub_df = df_main.query('follower_count < @percent99')\n",
    "\n",
    "\n",
    "fig = px.histogram(sub_df, \n",
    "                   x=\"follower_count\", \n",
    "                   nbins=100,\n",
    "                   color=\"label\",\n",
    "                   marginal=\"box\", # or violin, rug\n",
    "                   )\n",
    "\n",
    "fig.update_layout(barmode='overlay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "\n",
    "sub_df = df_main.query('follow_count.notna()')\n",
    "\n",
    "\n",
    "labels = ['0', '1', '3']\n",
    "hist_data = [sub_df[sub_df['label'] == int(x)]['follow_count'] for x  in labels]\n",
    "\n",
    "fig = ff.create_distplot(hist_data, labels,\n",
    "                         bin_size=[200, 200, 200], show_curve=True)\n",
    "\n",
    "# Add title\n",
    "fig.update(layout_title_text='Hist and Rug Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ml = df_main.copy(deep=True)\n",
    "\n",
    "# # removing na on label,\n",
    "# df_ml = df_ml.dropna(subset='label')\n",
    "\n",
    "# # df_ml['biography'] = df_ml['biography'].fillna('')\n",
    "# # df_ml['domain'] = df_ml['domain'].fillna('')\n",
    "# # df_ml['pronouns'] = df_ml['pronouns'].fillna('')\n",
    "\n",
    "\n",
    "# # removing agg columns \n",
    "# df_ml['posts_na_flag'] = df_ml['posts_days_diff'].isna().astype(int)\n",
    "# for col in df_ml.columns: \n",
    "#     if (col[:6] == 'posts_' and 'concat' not in col and 'posted_time' not in col) or 'dates_diff' in col: \n",
    "#         try:\n",
    "#             df_ml[col] = df_ml[col].fillna(df_ml[col].mean())\n",
    "#         except: \n",
    "#             df_ml = df_ml.drop(col, axis=1)\n",
    "#     elif 'concat ' in col or 'posted_time' in col: \n",
    "#         df_ml = df_ml.drop(col, axis=1)\n",
    "\n",
    "# # Adding comment feature \n",
    "# # df_ml['comment_length'] = df_ml['comment'].str.len()\n",
    "\n",
    "# # removing na on follow count\n",
    "# df_ml = df_ml.dropna(subset='follow_count')\n",
    "# # df_ml['biography'] = df_ml['biography'].apply(lambda x: 1 if len(x) > 0 else 0)\n",
    "# # df_ml['domain'] = df_ml['domain'].apply(lambda x: 1 if len(x) > 0 else 0)\n",
    "# # df_ml['pronouns'] = df_ml['pronouns'].apply(lambda x: 1 if len(x) > 0 else 0)\n",
    "# df_ml['label'] = df_ml['label'].astype(float)\n",
    "# for col in ['pronouns', 'domain', 'business_contact_method', 'business_category_name', 'category_name', 'category_enum', 'posts_concat_likes', 'posts_concat_is_video', 'posts_concat_video_views', 'posts_concat_comments', 'posts_concat_tagg_count', 'labelling_technique', 'outlier']: \n",
    "#     df_ml = df_ml.drop(col, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.isna().sum().tail(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df_ml.isna().sum().head(50).eq(0)\n",
    "cols = s[s].index\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.to_sql('ml', con, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "06d12861cad82bdcdde1b56bd9eda52e91f7df29dabbeda8f3d9112222750302"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
